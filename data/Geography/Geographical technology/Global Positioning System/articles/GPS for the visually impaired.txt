Since the Global Positioning System (GPS) was introduced in the late 1980s there have been many attempts to integrate it into a navigation-assistance system for blind and visually impaired people. Corsair is a GPS for pedestrians. It allows you to discover places around you and take you there. A new way of guidance has been developed by using the smartphone's vibration feature to indicate the direction to follow. This solution is particularly useful for people with visual impairments. Cydalion is a navigation aid for people with visual impairments for Tango-enabled devices. Cydalion detects objects (including their height), offers custom sounds, and has a personalized user interface. Lazarillo is based on Google Maps, OpenStreetMap and Foursquare alongside they own databases and with this information, Lazarillo collects the necessary data about the surroundings of the user to support the following features:  Was designed in France to compensate for the limitations of traditional GPS and smartphone applications for the blind and visually impaired .  The fruit of 8 years of research in collaboration with the CNRS, ANGEO is the only device capable of discretely, reliably guiding you when crossing areas where GPS satellites are masked.  When Apple introduced the iPhone 3GS in 2009, it was the first ever touch screen device accessible to the blind. iOS device usage has steadily increased among the blind and visually impaired population and numerous GPS apps targeting this user group have been developed since.  Ariadne GPS, developed by Luca Giovanni Ciaffoni, was released in June 2011 and was one of the first GPS apps specifically designed for blind and visually impaired users. It is based on Google map data and has the following features: BlindSquare is developed by MIPsoft and was first released in May 2012. It uses data from Foursquare and OpenStreetMap and offers a large feature set covering the needs of blind and visually impaired travelers.  It is based on Foursquare, Open Street Map, and Apple Maps data and supports the following features: iMove has been developed by EveryWare Technologies and was first released in January 2013. It is unique, because it lets users record sound clips and associate them with saved locations. iMove offers the following features: MyWay Classic was first released in January 2012 and is developed by the Swis Federation of the Blind. It has evolved into an app with a large set of features covering the needs of blind and visually impaired travelers. It uses Open Street Map data and includes the following features: Seeing Assistant move is developed by Transition Technologies S.A. and was first released in March 2013. It is the only GPS app designed for blind and visually impaired people that lets the user operate the app through predefined speech commands. It is based on Open Street Map and supports the following features: Sendero Seeing Eye GPS is developed by the Sendero Group in collaboration with several organizations for the blind (Seeing Eye, RNIB, Guide Dogs NSW ACT) and was first released in July 2013. The Seeing Eye GPS is a fully accessible turn-by-turn GPS iPhone app developed by Sendero Group. It has all the normal navigation features plus features unique to blind users, such as simple menu structure, automatic announcements of intersections and points of interest, and routes for both pedestrian and vehicle with heads-up announcements for approaching turns. It uses Foursquare and Google Places for points of interest and Google Maps for street info.  Seeing Eye is not available globally and is offered under various names: The Sendero apps include the following features: ViaOpta Nav is developed by Novartis Pharmaceuticals Corporation and was first released in August 2014. It is available for both IOS and Android devices. It is the only GPS app targeting blind and visually impaired users that offers the possibility to search for accessibility information for example information about intersections, tactile paving, and audible traffic signals. Although Open Street Map supports respective categories, this information is not very widely available yet in the map data itself. ViaOpta Nav uses Apple Maps (on iOS devices) and Google Maps (on Android devices) for address retrieval, and Open Street Map for route calculation, intersection information, and public points of interest. ViaOpta Nav supports the following main features: The Loadstone project is developing an open source software for satellite navigation for blind and visually impaired users. The software is free and runs currently on many different Nokia devices with the S60 platform under all versions of the Symbian operating system. A GPS receiver must be connected to the cell phone by Bluetooth. Many blind people around the world are using Nokia cell phones because there are two screen reader products for the S60 Symbian platform; Talks from Nuance Communications and Mobile Speak from the Spanish company Code Factory. This makes these devices accessible by output of synthetic speech and also allow the use of third party software, such as Loadstone GPS. The Loadstone developers, who are blind, are from Vancouver, Glasgow, and Amsterdam. Many users from around the world have contributed improvement proposals as they know exactly what functionality helps to increase their pedestrian mobility. Monty Lilburn and Shawn Kirkpatrick started the project in 2004. After the first development successes, they made it public in May 2006. Since then, other volunteers have found their way to this project of global self-help. The program is under the GNU General Public License (GPL), and was financed entirely by the private developers and by donations of users. This product provides blind people with more independence from the trading policy and prices of the few global vendors of accessible satellite navigation solutions. In large rural regions and developing or newly industrializing countries, nearly no exact map data is available in common map databases. As such, the Loadstone software provides users an option to create and store their own waypoints for navigation and share them with others. The Loadstone community is working on importing coordinates from free sources, such as the OpenStreetMap project. In addition they are searching for a sponsor of licenses for commercial map data, such as is offered by the company Tele Atlas. The other major supplier is Navteq, which belongs to Nokia. Lodestone is the name of a natural magnetic iron that was used throughout history in the manufacturing of compasses. Sighted owners of S60 devices can use Loadstone for leisure-time activities geocaching.  LoroDux was a project by Fachhochschule Hannover. Like in Loadstone the user is led by direction and distance information. The text on the screen is read out by a screenreader. Vibration-Only navigation is possible. Data can be imported from the OpenStreetMap project. The development is discontinued because the team prefers to use Java on Android for the future. LoroDux LoroDux  Mobile Geo is Code Factory’s GPS navigation software for Windows Mobile-based Smartphones, Pocket PC phones and personal digital assistants (PDAs). Powered by GPS and mapping technology from the Sendero Group, Mobile Geo is the first solution specifically designed to serve as a navigation aid for people with a visual impairment which works with a wide range of mainstream mobile devices. Though it is a separately licensed product, Mobile Geo is seamlessly  integrated with Code Factory’s popular screen readers – Mobile Speak for Pocket PCs and Mobile Speak for Windows Mobile Smartphones.  The Victor Trekker, designed and manufactured by HumanWare (previously known as VisuAide), was launched on March 2003. It is a personal digital assistant (PDA) application operating on a Dell Axim 50/51 or later replaced by HP IPAQ 2490B Pocket PC, adapted for the blind and visually impaired with talking menus, talking maps, and GPS information. Fully portable (weight 600g), it offered features enabling a blind person to determine position, create routes and receive information on navigating to a destination. It also provided search functions for an exhaustive database of point of interests, such as restaurants, hotels, etc. The PDA's touch screen is made accessible by a tactile keypad with buttons that is held in place with an elastic strap. It is fully upgradeable, so it can expand to accommodate new hardware platforms and more detailed geographic information. Trekker and Maestro, which is the first off-the-shelf accessible PDA based on Windows Mobile Pocket PC, are integrated and available since May 2005. The Trekker is no longer sold by Humanware; the successor "Trekker Breeze" is a standalone unit. The software has fewer features than the original Trekker.  The Trekker Breeze is standalone hardware. Routes need to be recorded before they can be used. POIs are supported. The BrailleNote GPS device is developed by Sendero Group, LLC, and Pulse Data International, now called HumanWare, in 2002. It is like a combination of a personal digital assistant, Map-quest software and a mechanical voice. With a receiver about the size of a small cell phone, the BrailleNote GPS utilizes the GPS network to pinpoint a traveler’s position on earth and nearby points of interest. The BrailleNote receives radio signals from satellites to chart the location of users and direct them to their destination with spoken information from the speech synthesizer. The system uses satellites to triangulate the carrier’s position, much like a ship finding its location at sea. Users can record points of interest such as local restaurants or any other location into the PDA’s database. Afterward, they can use keyboard commands on the unit’s keyboard to direct themselves to a specific point of interest. The French company Kapsys offers a navigation system without a display, that works with speech input and output, called Kapten. It was originally developed for cyclists but soon became a favourite in blind communities because of its low price compared to other accessible navigation solutions. Later Versions took feedback about accessibility into account. The Trinetra project aims to develop cost-effective, independence-enhancing technologies to benefit blind people. One such system addresses accessibility concerns of blind people using public transportation systems. Using GPS receivers and staggered Infrared sensors, information is relayed to a centralized fleet management server via a cellular modem. Blind people, using common text-to-speech enabled cell phones can query estimated time of arrival, locality, and current bus capacity using a web browser. Trinetra, spearheaded by Professor Priya Narasimhan, is an ongoing project at the Electrical and Computer Engineering department of Carnegie Mellon University. Additional research topics include item-level UPC and RFID identification while grocery shopping and indoor navigation in retail settings.  MoBIC means Mobility of Blind and Elderly people Interacting with Computers, which was carried out from 1994 to 1996 supported by the Commission of the European Union. It was developing a route planning system which is designed to allow a blind person access to information from many sources such as bus and train timetables as well as electronic maps of the locality. The planning system helps blind people to study and plan their routes in advance, indoors. With the addition of devices to give the precise current position and orientation of the blind pedestrian, the system could then be used outdoors. The outdoor positioning system is based on signals and satellites which give the longitude and latitude to within a metre; the computer converts this data to a position on an electronic map of locality. The output from the system is in the form of spoken messages. Drishti is a wireless pedestrian navigation system. It integrates several technologies including wearable computers, voice recognition and synthesis, wireless networks, Geographic information system (GIS) and GPS. It augments contextual information to the visually impaired and computed optimized routes based on user preference, temporal constraints (e.g. traffic congestion), and dynamic obstacles (e.g. ongoing ground work, road blockade for special events). The system constantly guides the blind user to navigate based on static and dynamic data. Environmental conditions and landmark information queries from a spatial database along their route are provided on the fly through detailed explanatory voice cues. The system also provides capability for the user to add intelligence, as perceived by the blind user, to the central server hosting the spatial database. In 1985, Jack Loomis, a Professor of Psychology at the University of California, Santa Barbara, came up with the idea of a GPS-based navigation system for the visually impaired. A short unpublished paper (Loomis, 1985) outlined the concept and detailed some ideas for implementation, including the idea of a virtual sound interface. Loomis directed the project for over 20 years, in collaboration with Reginald Golledge (1937–2009), Professor of Geography at UCSB, and Roberta Klatzky, Professor of Psychology (now at Carnegie Mellon University). Their combination of development and applied research was supported by three multi-year grants from the National Eye Institute (NEI) and another multi-year consortium grant from the National Institute on Disability and Rehabilitation Research (NIDRR), headed by Michael May of Sendero Group. In 1993, the UCSB group first publicly demonstrated the Personal Guidance System (PGS) using a bulky prototype carried in a backpack. Since then, they created several versions of the PGS, one of which was carried in a small pack worn at the waist. Their project mostly focused on the user interface and the resulting research has defined the legacy of the project. As indicated earlier in this entry, several wearable systems are now commercially available. These systems provide verbal guidance and environmental information via speech and Braille displays. But just as drivers and pilots want pictorial information from their navigation systems, survey research by the UCSB group has shown that visually impaired people often want direct perceptual information about the environment. Most of their R&D has dealt with several types of “spatial display”, with researchers Jim Marston and Nicholas Giudice contributing to the recent efforts. The first is a virtual acoustic display, which provides auditory information to the user via earphones (as proposed in the 1985 concept paper). With this display, the user hears important environmental locations, such as turn points along the route and points of interest. The labels of these locations are converted to synthetic speech and then displayed using auditory direction and distance cues, such that the spoken labels appear in the auditory space of the user. A second type of display, which the group calls a “haptic pointer interface”, was inspired by the hand-held receiver used in the Talking Signs© system of remote signage. The user holds a small wand, to which are attached an electronic compass and a small loudspeaker or vibrator. When the hand is pointing toward some location represented in the computer database, the user hears a tone or feels a vibration. Supplementary verbal information can be provided by synthetic speech. The user moves toward the desired location by aligning the body with the hand while maintaining the "on-course" auditory or vibratory signal. Other variants of the pointer interface involve putting the compass on the body or head and turning the body or head until the on-course signal is perceived. Six published route-guidance studies indicate that spatial displays provide effective route guidance, entail less cognitive load than speech interfaces, and are generally preferred by visually impaired users.  Prof. W. Balachandran is the pioneer and the head of GPS research group at Brunel University. He and his research team are pursuing research on navigation system for blind and visually impaired people. The system is based on the integration of state of the art current technologies, including high-accuracy GPS positioning, GIS, electronic compass and wireless digital video transmission (remote vision) facility with an accuracy of 3~4m. It provides an automated guidance using the information from daily updated digital map datasets e.g. roadworks. If required the remote guidance of visually impaired pedestrians by a sighted human guide using the information from the digital map and from the remote video image provides flexibility. The difficulties encountered include the availability of up to date information and what information to offer including the navigation protocol. Levels of functionality have been created to tailor the information to the user’s requirements. NOPPA navigation and guidance system was designed to offer public transport passenger and route information using GPS technology for the visually impaired. This was a three-year (2002~2004) project in VTT Industrial Systems in Finland. The system provides an unbroken trip chain for a pedestrian using buses, commuter trains and trams in three neighbor cities’ area. It is based on an information server concept, which has user-centered and task oriented approach for solving information needs of special needs groups. In the system, the Information Server is an interpreter between the user and Internet information systems. It collects, filters and integrates information from different sources and delivers results to the user. The server handles speech recognition and functions requiring either heavy calculations or data transfer. The data transfer between the server and the client is minimized. The user terminal holds speech synthesis and most of route guidance. NOPPA can currently offer basic route planning and navigation services in Finland. In practice, map data can have outdated information or inaccuracies, positioning can be unavailable or inaccurate, or wireless data transmission is not always available. NAVIG is a multidisciplinary project, with fundamental and applied aspects. The main objective is to increase the autonomy of blind people in their navigation capabilities. Reaching a destination while avoiding obstacles is one of the most difficult issue that blind individuals have to face. Achieving autonomous navigation will be pursued indoor and outdoor, in known and unknown environments. The project consortium is composed by two research centers in computer sciences specialized in human-machine interaction (IRIT) for handicapped people and in auditory perception, spatial cognition, sound design and augmented reality (LIMSI). Another research center is specialized in human and computer vision (CERCO), and two industrial partners are active in artificial vision (Spikenet Technology) and in pedestrian geolocalisation (Navocap). The last member of the consortium is an educational research center for the visually impaired (CESDV – IJA, Institute of Blind Youth).  TANIA is a project founded at the University of Stuttgart, Germany. The hardware is based on GPS and RFID. It allows navigation for blind and deafblind persons with step accuracy. It only works where special maps have been created for the system.  Wayfinder Access was a GPS solution from the Swedish company Wayfinder Systems AB. This application for Symbian phones was designed especially to work with screen readers, such as Mobile Speak from Code Factory or TALKS from Nuance Communications and offers text-to-speech technology. It is able to take the special needs of the blind and visually impaired into consideration. Symbian screen reader software offers more than just the reading of the application’s screens, but also supports Braille devices. Highlights of Wayfinder Access include, but are not limited to: The Wayfinder Access Service was shut down in 2011 after the company was taken over by Vodafone. 