The administration of drugs to whole populations irrespective of disease status is referred to as mass drug administration (MDA). This article describes the administration of antimalarial drugs to whole populations an intervention which has been used as a malaria-control measure for more than 70 years. Recent proposals to eliminate or even to eradicate malaria have led to a renewed interest in mass drug administrations in areas with very high malaria endemicity.  Drugs have been administered either directly as a full therapeutic course of treatment or indirectly through the fortification of salt. Mass drug administrations were generally unsuccessful in interrupting transmission but, in some cases, had a marked effect on parasite prevalence and on the incidence of clinical malaria. MDAs are likely to encourage the spread of drug-resistant parasites and so have only a limited role in malaria control. They may have a part to play in the management of epidemics and in the control of malaria in areas with a very short transmission season. In order to reduce the risk of spreading drug resistance, MDAs should use more than one drug and, preferably include a drug, such as an artemisinin, which has an effect on gametocytes. MDAs have low acceptance in areas with low malaria endemicity. Another example of mass drug administration is mass deworming of children to remove helminth infections (intestinal worms). Reports of attempts to control malaria through mass treatment with antimalarial drugs date back to at least 1932.  In the 1950s, the WHO included mass drug administration (MDA) of antimalarial drugs as a tool for malaria eradication ‘in exceptional conditions when conventional control techniques have failed.  In 1971, the WHO expert committee on malaria still recommended MDA in special circumstances.  Subsequently, MDA was linked to the emergence of drug resistance and its overall benefit was questioned.     Concomitantly, the goal of malaria eradication was replaced by one of prevention of malaria morbidity and mortality through the provision of effective treatment. Considering the short lasing benefit of mass drug administration one modification has been to repeat mass drug administrations which has led to the development of intermittent preventive therapy. Two methods of MDA, direct and indirect, have been used. In direct MDA, also referred to as ‘Mass drug treatment’, a therapeutic dose of the antimalarial drug, usually in the form of tablets, is given to an entire population. In indirect MDA, the antimalarial drug is added to food stuff, usually salt. The first, well documented use of direct MDA took place in a rubber plantation in Liberia in 1931.  Two doses of the 8-aminoquinoline plasmoquine were given weekly to workers and their families in two camps. The prevalences of malaria parasite infections in humans and anopheline mosquitoes before and after treatment were studied. The authors concluded that ‘the fall in the mosquito infection rate of the two plasmoquine treated camps was so large as to indicate a local disappearance, or at least a great reduction, in gametocyte carriers in the treated population’. No long-term follow up data were provided for this study or most of the trials reported subsequently. The next documented use of MDA in sub-Saharan Africa took place in 1948 and 1949 in tea estates in Kericho, Kenya.  Ten thousand inhabitants of the tea estates received twice weekly proguanil from April to July 1948. The intervention was supplemented with DDT spraying in March and June of the following year. Before the intervention the mean malaria incidence in July, the peak of the malaria transmission season, was 56 cases per 1000 population. Following the intervention 4 malaria cases were detected in July 1949. The author therefore recommended continuation of twice weekly proguanil prophylaxis on the estates. The Nandi district of Kenya was the scene of a large MDA in 1953 and 1954.    The target population of 83,000 received a single dose of pyrimethamine at the beginning of the malaria season in 1953 and 1954. The coverage was estimated to be around 95%.  Before the intervention severe malaria epidemics had been reported in the area. Following the intervention the parasite prevalence dropped from 23% to 2.3%.  The author states that in a control area parasite prevalence rose over the same period  to over 50%. It was felt that the MDA was effective in curbing severe malaria epidemics. In the following three years, 1955 to 1957, pyrimethamine administration was replaced with Dieldrin spraying to consolidate malaria control, which makes an assessment of the long-term effect of this MDA impossible. During a pilot programme in Uganda in 1959 mass administration of chloroquine / pyrimethamine was combined with spraying of residual insecticides (DDT).  The success of the pilot programme led to a larger study targeted at a population of 16,000. Because of logistic problems, only half of the target population received the first round of MDA. According to the investigators, the intervention resulted in the eradication of the vector and rapid elimination of malaria from the area.  Two large trials of MDA combined with household spraying with DDT were conducted in Cameroun and Upper Volta (Burkina Faso) in 1960–1961.    In both trials, substantial reductions in the prevalence of parasitaemia were achieved but transmission was not interrupted.  In Bobo-Dioulasso, where primaquine was used in combination with either chloroquine or amodiaquine, the prevalence of gametocytes and Anopheles gambiae sporozoites were reduced substantially. A MDA was also combined with DDT spraying in Zanzibar (Dola 1974). After the MDA, the parasite prevalence in children decreased, but the overall parasite prevalence increased slightly, thus failing to deplete the reservoir of infection.  Two trials in Northern Nigeria combined multiple rounds of MDA and insecticide spraying. The first trial, in Kankiya, included 11 rounds of MDA combined with 8 rounds of DDT indoor spraying.  The study was based on computer-aided models that showed that MDA could eradicate malaria in the study area if combined with an appropriate ‘insecticide attack’.  Following MDAs, parasite prevalence dropped from 19% to 1%. The investigators did not consider this a success because parasite prevalence increased again after the interventions were stopped. Entomological indices also showed only a temporary reduction in transmission, which was completely reversed after the control measures ceased. Because the investigators felt that the failure of the trial to interrupt transmission was due to operational inadequacies, they recommended a much larger and more sophisticated evaluation of insecticide spraying combined with MDA. This recommendation helped to launch the Garki project, also in Northern Nigeria, in 1969.  In the Garki project, all 164 study villages in the catchment area were sprayed with propoxur, a residual insecticide. In addition, in 60 villages, MDA with sulfalene / pyrimethamine was given at 10-week intervals for two years. In two small village clusters, house spraying was supplemented with larvicide and MDA every two weeks. With biweekly MDA, parasite prevalence fell to 1% in the dry season and to 5% in the rainy season. MDA given every 10 weeks resulted in a parasite prevalence of 2% in the dry season and 28% in the rainy season. Transmission was not interrupted with either MDA regime. The authors concluded that spraying of residual insecticides and MDA did not result in a sustainable interruption of malaria transmission. In 1999 in The Gambia residents living in 33 of 42 villages in the catchment area received a single dose of sulfadoxine / pyrimethamine (SP) combined with artesunate while the residents of nine control villages received placebo.  Following the MDA, 1388 children ≤10 years of age  living in nine control villages and in nine matched villages which had been allocated active treatment were kept under surveillance for clinical malaria throughout the transmission season. Initially, during July and August, the mean malaria incidence rate in treated villages was significantly lower than in the control villages. In subsequent months, the incidence was slightly higher in the MDA villages. The difference between the two groups was not statistically significant. Overall no benefit of the mass drug administration was detected over the course of the malaria transmission season. A mass drug administration campaign using S/P, artesunate and primaquine was completed in Moshi district, Tanzania in 2008. The findings have yet to be published. Outside of sub-Saharan Africa one of the larger reported malaria-control projects using MDA took place in Nicaragua in 1981 following the overthrow of the Somoza regime.  An estimated 70% of Nicaragua’s total population (1.9 million people) received chloroquine and primaquine during the peak period of disease transmission (November). An estimated 9200 cases of malaria were prevented. The campaign had better results in preventing and curing malaria infections than in interrupting transmission. However, the mass administration of antimalarials was not sustainable and, as with other malaria-control efforts, collapsed following the return of politically conservative forces.  In three malaria-control projects conducted in the Indian states of Andhra Pradesh, Uttar Pradesh, and Orissa in the early 1960s, MDA had an ancillary role and was mentioned only briefly in reports on these interventions.    More detailed information is available following a focal outbreak in two villages in Gujarat State during 1978-1979.  Here a mass administration of chloroquine was part of a programme of intensified surveillance, case management, health education, and residual spraying. The incidence of malaria decreased so that, by the end of 1979, the authors considered the intervention to be a success. In 1980, in areas of Andhra Pradesh State in India, residual spraying was combined with a MDA.  During the period of lowest malaria incidence a single dose of chloroquine plus primaquine was distributed to the whole population in eight villages. A second dose was given after an interval of 2–3 months. This project failed to reduce malaria incidence and was considered to be a failure. In 1984, MDA was added to the distribution of insecticide-impregnated bed nets (ITNs) in Sabah (Malaysia), but this failed to interrupt malaria transmission.  A MDA in Sumatra, Indonesia in 1987 focused on schoolchildren.  Eight months after the MDA, Plasmodium falciparum prevalence had decreased from 14% to 1%. The only reported project with an MDA component which succeeded in permanently interrupting malaria transmission took place on the island of Aneityum, Vanuatu.   Starting in September 1991, three malaria-control activities were employed – permethrin-impregnated bednets, larvivorous fish and the administration of three antimalarials. This MDA comprised 300 mg chloroquine base and 45 mg pyrimethamine weekly for nine weeks. An additional 300 mg chloroquine and 75 mg pyrimethamine plus 1500 mg sulfadoxine was added to this regimen in the first, fifth, and ninth week. Children received an adjusted equivalent of the adult dose. Follow-up consisted of yearly parasite surveillance. During the seven surveillance years following the MDA, no P.falciparum infections were detected. MDA is included in the malaria-control policy of the People’s Republic of China. Following the first malaria-control phase from 1955 to 1962, which was mostly focused on malaria surveys, mass administrations were added to vector control measures and improved case management in 10 of China’s 33 provinces.  The drugs used in the administrations, mostly chloroquine and piperaquine, were provided free of charge by the central government. The economic reforms instituted by Deng Xiaoping, which ultimately put an end to the provision of free health care through the central government and the emergence of resistance against the most widely used antimalarials modified the use of mass drug administrations after 1980. MDAs are now targeted at high-risk populations, specifically non-immune migratory workers who receive repeated courses during the high transmission season. According to government guidelines, piperaquine, chloroquine, or sulfadoxine combined with primaquine can be used for mass administrations.  The artemisinin derivatives are not used in mass drug administrations and are reserved for treatment failures. Malaria burden and control measures are shown in Table 1. Between 1990 and 2000 the malaria prevalence dropped from 10.6 to 1.9 / 100,000, the number of reported malaria cases dropped from 117,359 to 24,088 while the number of reported deaths attributable to malaria remained stable.  These data, reported to the national government, depend on reporting from health care providers and like all data depending on passive surveillance tend to underestimate the true disease burden. However, there is no reason to think that the level of underreporting has changed over the last decade. Therefore, the proportional reduction in malaria disease burden is likely to be true. Malaria-control measures, including MDA, as well as major ecologic changes during the second half of the last century are likely to have been responsible for the more than 100-fold reduction in malaria burden in China since the initial surveys in 1955.  The widespread use of antimalarials has been followed by the emergence of drug resistance especially in regions with high drug use. By 1995 more than 95% of P.falciparum strains isolated in the South of Yunnan province were found to be resistant to chloroquine, and piperaquine while in the remainder of Yunnan and Hainan province the resistance rates were 85%and 38% respectively.  A different approach to MDA consists of adding an antimalarial to an essential foodstuff, usually salt. Chloroquinized salt for malaria suppression was introduced by Pinotti in 1952 and gave promising results in a number of field trials and malaria-control programmes in Brazil.    In 1959, the WHO conducted a trial in West New Guinea (later known as Irian Jaya).  Salt crystals were mixed with pyrimethamine so as to provide a 0.07% pyrimethamine salt. As there were no shops in the catchment area, each family unit received fortnightly a quantity of salt from the local teacher or another member of the village community. Within three and a half months of the onset of the campaign, clinically significant levels of pyrimethamine resistance were reported. It was then decided to mix the remaining stock of pyrimethaminized salt with chloroquine powder. The chloroquine base content was 0.04% or 140 mg per adult per week based on a 5g per day salt consumption. The emergence of chloroquine resistance was investigated, but this was not detected. The distribution of medicated salts otherwise had no effect and it was concluded that ‘Pinotti’s method holds no prospect of malaria eradication…’. The explanation for this finding given by the author is that ‘the salt consumption by children was too small to reduce significantly the parasite reservoir of the younger age groups’. Between 1961 and 1965, the use of chloroquinized salt was made compulsory over an area of 109,000km2 in Guyana, covering a population of 48,500 individuals.  The chloroquinized salt was prepared at a state salt plant so as to provide a 0.43% chloroquine concentration. The salt was sold in two pound plastic bags. The state held the monopoly for the salt. The only alternative source was salt smuggled from Brazil. Although the chloroquinized salt was used, its popularity was limited by the occurrence of a photo-allergic dermatitis popularly called ‘salt itch’ noted in all treatment areas. Chloroquine resistance was first observed in 1962 in the area with the lowest relative uptake of chloroquinized salt. In the course of the following months, a complete replacement of the susceptible strains with resistant P. falciparum strains was observed. Following the reintroduction of DDT spraying, the prevalence of P. falciparum declined. In Southeast Asia, the medicated salt project at Pailin, on the Kampuchea-Thai border, demonstrated how drug resistance can develop when a large population of P. falciparum undergoing high transmission rates is exposed to intense drug pressure.  The project was launched in 1960 and covered a population of approximately 20,000. Sea salt was mixed with pyrimethamine at a concentration of 0.05%. Between 1960 and 1961, 77 tons of medicated salt were distributed in the area. After widespread pyrimethamine resistance was reported, pyrimethamine was replaced by chloroquine. From 1961 to 1962, 75 tons of chloroquine were distributed.  In two indicator districts, the parasite rates decreased from 40% to 7% and from 27% to 14%.  Chloroquine resistant P.falciparum isolates were first detected in Pailin in 1962 which appeared to be widespread by 1966. However no survey was undertaken to document the prevalence in the area. The factors leading to the emergence and spread of drug resistance appear to have been the continuous introduction of non-immune migrants, attracted by the promise of quick wealth from mining of precious stones, and prolonged drug pressure resulting from individual drug consumption and mass drug administration. Unrelated to MDAs the emergence of artemisinin resistant P.falciparum strains was reported in Pailin in 2008, this may have been related to overuse of artemisinin derivateves including counterfeit drugs but was not related to programmatic MDAs.    Further malaria-control projects have used MDA, but have never been published, or have been published as technical reports.   Whether MDAs can be considered successful or not depends on the expectation of what they might achieve; many studies do not define whether their main aim was to interrupt transmission or to control disease. When MDAs were used as part of an attempt to interrupt transmission completely, they almost always failed. Only one project, conducted on Aneityum, a small isolated island in the Pacific, succeeded in permanently interrupting transmission using MDA as one of several malaria-control strategies. However, although unable to interrupt transmission, many MDA projects led to a marked reduction in parasite prevalence and probably had a marked also transient effect on malaria-related morbidity and mortality. Most of the early trials used study designs which would now be considered inadequate to provide a definitive answer on study outcome. For example, before-and-after comparisons were used frequently. Such comparisons are especially unreliable for vector-borne diseases which may show marked variations in incidence from season to season as well as from year to year. Furthermore, in several studies only a single intervention and control area or group were compared despite the fact a single control group cannot provide statistically interpretable results (see n = 1 fallacy). The deficiencies in the study designs mentioned above reflect the evolution of research methodology over the last 50 years. The evaluation of an intervention such as MDA is complicated by the fact that the effect of the intervention on transmission can only be measured at the community and not at the individual level. Trial methods which use a community, a village, or a cluster as unit of inference have taken longer to evolve than those used for individually randomized trials. There are, with some notable exceptions, few properly designed and analysed cluster randomized trials conducted by health care researchers prior to 1978. One major handicap for researchers who need to use the cluster approach, besides the need for a large sample size, is the need to use statistical methods that differ from the familiar methods used in individually randomized trials. Significant progress has been made in the development of statistical methods for the analysis of correlated data. The present unpopularity of MDA is not only due to doubts regarding the health benefit of this intervention but to the fear that MDAs will facilitate the spread of drug resistance. Concern that MDA would cause pyrimethamine and later chloroquine resistance was first raised in the early 1960s. Circumstantial evidence linked the use of medicated salts to the emergence of chloroquine resistance in the 1980s: Chloroquine resistance emerged first in three foci, namely South America (Colombia, Venezuela, Brazil), Southeast Asia (Thailand/Kampuchea), and Africa (Tanzania/Kenya). Payne has argued that the one common factor between these three epidemiologically diverse areas was widespread distribution of medicated salts prior to the emergence of chloroquine resistance.  In contrast to indirect MDA, emergence of drug resistance has not been linked to the administration of therapeutic doses of antimalarials through direct MDA programmes. The likely explanation lies in the different pharmacokinetic profiles that result from these two methods of drug administration. The administration of therapeutically dosed antimalarial drugs results in a single peak drug level which kills all susceptible strains. Only during the terminal half life of the drug when the concentration drops below the Cmin, the inhibitory concentration which kills the large majority of a parasite population, will new infections with more resistant strains have a survival advantage. Thus drugs with a very short terminal half-life, including artemisinin derivatives, carry a lower risk of selecting resistant parasites than longer acting drugs. In contrast, the administration of medicated salts is likely to result in drug levels undulating in the sub-lethal range, which reach a steady state after several doses have been administered. The situation is worse if drugs such as chloroquine are used which accumulate progressively. This situation, a steady increase in drug concentration, is identical to the experimental design used for the in vitro induction of drug resistance.  Medicated salt projects can be considered as large scale in vivo experiments designed to select resistant parasites. The administration of antimalarials to large numbers of individuals with little or no preliminary screening could result in significant toxicity as nearly all antimalarials in common use can occasionally cause serious adverse events. For example, the widespread use of 8-aminoquinolines in areas where Glucose-6-phosphate dehydrogenase deficiency is common carries the risk of precipitating episodes of haemolysis. Few MDA projects have reported specifically on adverse events. No life-threatening outcomes have been reported as a result of an MDA but a rare serious adverse event such as a blood dyscrasia would probably not have been detected without active surveillance for adverse events which was not reported in any of the studies. There is a theoretical risk that administration of antimalarial drugs during the course of MDAs to women in the first trimester of pregnancy, some of whom may not know that they are pregnant, could lead to foetal abnormalities. The benefit of malaria control has to be weighed against potential problems. Hence MDA is likely to be only used in areas with very high malaria endemicity. 