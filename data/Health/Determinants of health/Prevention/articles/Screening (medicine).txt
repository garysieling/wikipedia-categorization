Screening, in medicine, is a strategy used in a population to identify the possible presence of an as-yet-undiagnosed disease in individuals without signs or symptoms. This can include individuals with pre-symptomatic or unrecognized symptomatic disease. As such, screening tests are somewhat unusual in that they are performed on persons apparently in good health. Screening interventions are designed to identify disease in a community early, thus enabling earlier intervention and management in the hope to reduce mortality and suffering from a disease. Although screening may lead to an earlier diagnosis, not all screening tests have been shown to benefit the person being screened; overdiagnosis, misdiagnosis, and creating a false sense of security are some potential adverse effects of screening. Additionally, some screening tests can be inappropriately overused.   For these reasons, a test used in a screening program, especially for a disease with low incidence, must have good sensitivity in addition to acceptable specificity.  Several types of screening exist: universal screening involves screening of all individuals in a certain category (for example, all children of a certain age). Case finding involves screening a smaller group of people based on the presence of risk factors (for example, because a family member has been diagnosed with a hereditary disease). Screening interventions are not designed to be diagnostic, and often have significant rates of both false positive and false negative results. In 1968, the World Health Organization published guidelines on the Principles and practice of screening for disease, which often referred to as Wilson's criteria.  The principles are still broadly applicable today: In 2008, with emergence of new genomic technologies, the WHO synthesised and modified these with the new understanding as follows: Synthesis of emerging screening criteria proposed over the past 40 years   In many countries there are population-based screening programmes. In some countries, such as the UK, these operate at a national level. Common screening programmes include: Most public school systems in the United States screen students periodically for hearing and vision deficiencies and dental problems. Screening for spinal and posture issues such as scoliosis is sometimes carried out, but is controversial as scoliosis (unlike vision or dental issues) is found in only a very small segment of the general population and because students must remove their shirts for screening. Many states no longer mandate scoliosis screenings, or allow them to be waived with parental notification.  Medical equipment used in screening tests is usually different from equipment used in diagnostic tests as screening tests are used to indicate the likely presence or absence of a disease or condition in people not presenting symptoms; while diagnostic medical equipment is used to make quantitative physiological measurements to confirm and determine the progress of a suspected disease or condition. Medical screening equipment must be capable of fast processing of many cases, but may not need to be as precise as diagnostic equipment. Screening can detect medical conditions at an early stage before symptoms present while treatment is more effective than for later detection. In the best of cases lives are saved. Like any medical test, the tests used in screening are not perfect. The test result may incorrectly show positive for those without disease (false positive), or negative for people who have the condition (false negative). Limitations of screening programmes can include: Screening for dementia in the English NHS is controversial because it could cause undue anxiety in patients and support services would be stretched. A GP reported "The main issue really seems to be centred around what the consequences of a such a diagnosis is and what is actually available to help patients."  To many people, screening instinctively seems like an appropriate thing to do, because catching something earlier seems better.  However, no screening test is perfect.  There will always be the problems with incorrect results and other issues listed above. Before a screening program is implemented, it should ideally be looked at to ensure that putting it in place would do more good than harm. The best studies for assessing whether a screening test will increase a population's health are rigorous randomized controlled trials. When studying a screening program using case-control or, more usually, cohort studies, various factors can cause the screening test to appear more successful than it really is. A number of different biases, inherent in the study method, will skew results. Screening can certainly improve outcomes, but this must be confirmed with proper statistical analysis, not simplistic comparison of numbers. The intention of screening is to diagnose a disease earlier than it would be without screening. Without screening the disease may be discovered later, when symptoms appear. Even if in both cases a person will die at the same time, because we diagnosed the disease earlier with screening the survival time since diagnosis is longer with screening; but life span has not been prolonged, and there will be added anxiety as the patient must live with knowledge of the disease for longer. Looking at statistics of survival time since diagnosis, screening will show an increase (this gain is called lead time). If we do not think about what survival time actually means in this context, we might attribute success to a screening test that does nothing but advance diagnosis; comparing statistics of mortality due to a disease in a screened and unscreened population gives more meaningful information. Many screening tests involve the detection of cancers. It is often hypothesized that slower-growing tumors have better prognoses than tumors with high growth rates. Screening is more likely to detect slower-growing tumors (due to longer pre-clinical sojourn time), which may be less deadly. Thus screening may tend to detect cancers that would not have killed the patient or even been detected prior to death from other causes. Not everyone will partake in a screening program. There are factors that differ between those willing to get tested and those who are not. If people with a higher risk of a disease are more likely to be screened, for instance women with a family history of breast cancer are more likely than other women to join a mammography program, then a screening test will look worse than it really is: negative outcomes among the screened population will be higher than for a random sample. Selection bias may also make a test look better than it really is. If a test is more available to young and healthy people (for instance if people have to travel a long distance to get checked) then fewer people in the screening population will have negative outcomes than for a random sample, and the test will seem to make a positive difference. Screening may identify abnormalities that would never cause a problem in a person's lifetime. An example of this is prostate cancer screening; it has been said that "more men die with prostate cancer than of it".  Autopsy studies have shown that a high proportion of elderly men who have died of other causes are found to have had prostate cancer. Aside from issues with unnecessary treatment (prostate cancer treatment is by no means without risk), overdiagnosis makes a study look good at picking up abnormalities, even though they are sometimes harmless. Overdiagnosis occurs when all of these people with harmless abnormalities are counted as "lives saved" by the screening, rather than as "healthy people needlessly harmed by overdiagnosis". The best way to minimize these biases is to use a randomized controlled trial. These need to be very large[clarification needed], and very strict in terms of research procedure. Such studies take a long time and are expensive, but provide the best information for evidence-based medicine. 