Language acquisition by deaf children parallels the development of any children acquiring spoken language as long as there is full access to language from birth.  Despite limited access to spoken language, communication and language exposure are fundamental to deaf infants' general cognitive development and their engagement with their surroundings. While a growing number of deaf children in the developed world receive hearing aids and/or cochlear implants to support spoken language acquisition   there are Deaf communities around the world that use signed languages. Infants born to signing parents, or exposed immersively to fluent sign language models at a young age, generally acquire sign language natively.  During the first year of life, all infants are primed to acquire information about the language in their environment.   Deaf infants immersed in fluent sign language from birth develop native language skills in that sign language in the same manner as any other child acquiring a language natively.    The early experience of deaf children, however, is highly variable and frequently atypical from a language acquisition perspective.  More than 95% of deaf children are born to hearing, non-signing families.  New parents with a deaf infant are faced with a range of options for how to interact with their newborn, and may try several methods that include different amounts of sign language, oral/auditory language training, and communicative codes invented to facilitate acquisition of spoken language.   In addition, parents may decide to use cochlear implants or hearing aids with their infants.  According to one US-based study from 2008, approximately 55% of eligible deaf infants received cochlear implants.   A study in Switzerland found that 80% of deaf infants were given cochlear implants as of 2006  and the numbers have been steadily increasing.  While cochlear implants provide auditory stimulation, not all children succeed at acquiring spoken language completely.  Children who received cochlear implants before twelve months old were found to be significantly more likely to perform at age-level standards for spoken language than children who received implants later.   About three percent of deaf children are born to two deaf parents, with one percent born to one hearing and one deaf parent. :153, 155 About 96% of deaf children are born to hearing parents. :153, 155 The majority of these children receive hearing aids and/or cochlear implants, and are taught to listen and to use spoken language using these devices. Research shows that deaf children who listen and speak to communicate, but do not use sign language have better communication outcomes   and social well-being  than Deaf children who use sign language. The general stages of language acquisition are the same whether the language is spoken or signed.  There are certain unique features of sign language acquisition due to the visual/manual modality and these differences can help to distinguish between universal aspects of language acquisition and aspects that may be affected by early experience.  The very earliest linguistic tasks facing newborns are perceptual.  Babies need to determine what basic linguistic elements are used in their native language to create words (their phonetic inventory). They also need to determine how to segment the continuous stream of language input into phrases and eventually words.  From birth, they have an attraction to patterned linguistic input, which is evident whether the input is spoken or signed.    They use their sensitive perceptual skills to acquire information about the structure of their native language, particularly prosodic and phonological features.  Sign languages have natural prosodic patterns and infants are sensitive to these prosodic boundaries even if they have no specific experience with sign languages.  6-month-old hearing infants with no sign experience also preferentially attend to sign language stimuli over complex gesture, indicating that they are perceiving sign language as meaningful linguistic input.  Since infants attend to spoken and signed language in a similar manner, several researchers have concluded that much of language acquisition is universal, not tied to the modality of the language, and that sign languages are acquired and processed very similarly to spoken languages, given adequate exposure.    At the same time, these and other researchers point out that there are many unknowns in terms of how a visual language might be processed differently than a spoken language, particularly given the unusual path of language transmission for most deaf infants.   Research shows that Deaf parents with deaf infants are more successful than hearing parents at capturing moments of joint attention when signing, which are privileged language learning moments.  Deaf mothers are more adept at ensuring that the infant is visually engaged prior to signing  and use specific modifications to their signing, referred to as child-directed sign  to gain and maintain their children's attention. Just as in child-directed speech (CDS), child-directed signing is characterized by slower production, exaggerated prosody, and repetition.  Due to the unique demands of a visual language, child-directed signing also includes tactile strategies and relocation of language into the child's line of vision.   Language acquisition strategies for signing deaf children are different than those appropriate for hearing children, or for deaf children who successfully use hearing aids and/or cochlear implants. For parents with deaf children who do not use amplification (hearing aids or cochlear implants), joint attention (an important component to language development) can be problematic. Hearing children can watch their environment and listen to an adult comment on it. However, children who do not hear have to switch their visual attention back and forth between stimuli.  Strategies for nonverbal communication include using facial expressions and body language to show emotion and reinforce the child's attention to their caregiver. To attract and direct a deaf child's attention, caregivers can break his line of gaze using hand and body movements, touch, and pointing to allow language input. In order to make language salient,[clarification needed] parents should use short, simple sentences so that the child's attention doesn’t have to be divided for too long. Finally, to reduce the need for divided attention, a caregiver can position themselves and objects within the child's visual field so that language and the object can be seen at the same time. For deaf children who use listening and spoken language as their primary mode of communication, their families will often participate in Auditory-verbal therapy, a means of enhancing the innate language and listening skills of deaf children. Most children who receive appropriate amplification before the age of 18 months and receive appropriate auditory-verbal instruction will follow language-learning trajectories of their peers who have typical hearing.  ASL employs signs made by moving one's hands along with one's facial expressions and body language. Some studies indicate that if a deaf child learns sign language, he or she will be less likely to learn spoken languages because they will lose motivation.  However, Humphries insists that there is no evidence for this.  Manually coded English is any one of a number of different representations of the English language that uses manual signs to encode English words visually. Although MCE uses signs, it is not a language like ASL; it is an encoding of English that uses hand gestures to make English visible in a visual mode. Most types of MCE use signs borrowed or adapted from American Sign Language, but use English sentence order and grammatical construction. Numerous systems of manually encoded English have been proposed and used with greater or lesser success.  Methods such as Signed English, Signing Exact English,  Linguistics of Visual English, and others use signs borrowed from ASL along with various grammatical marker signs, to indicate whole words, or meaning-bearing morphemes like -ed or -ing. Because MCE systems are encodings of English which follow English word order and sentence structure, it's possible to sign MCE and speak English at the same time.  This is a technique that is used in order to teach deaf children the structure of the English language not only through the sound and lip-reading patterns of spoken English, but also through manual patterns of signed English. Because of the close connection between the two, it is easier for hearing people to learn MCE than ASL.  Cued Speech is a hybrid, oral/manual system of communication used by some deaf or hard-of-hearing people. It is a technique that uses handshapes near the mouth ("cues") to represent phonemes that can be challenging for some deaf or hard-of-hearing people to distinguish from one another through speechreading ("lipreading") alone. It is designed to help receptive communicators to observe and fully understand the speaker. Cued speech is not a signed language, and it does not have any signs in common with ASL. It is a kind of augmented speechreading, making speechreading much more accurate and accessible to deaf people. The handshapes by themselves have no meaning; they only have meaning as a cue in combination with a mouth shape, so that the mouth shape 'two lips together' plus one handshape might mean an 'M' sound, the same shape with a different cue might represent a 'B' sound, and with a third cue might represent a 'P' sound. Some research shows a link between lack of phonological awareness and reading disorders, and indicate that teaching cued speech may be an aid to phonological awareness and literacy.  Another manual encoding system used by the deaf and which has been around for more than two centuries is fingerspelling. Fingerspelling is a system that encodes letters and not words or morphemes, so is not a manual encoding of English, but rather an encoding of the alphabet. As such, it is a method of spelling out words one letter at a time using 26 different handshapes. In the United States and many other countries, the letters are indicated on one hand  and go back to the deaf school of the Abbe de l'Epee in Paris.  Since fingerspelling is connected to the alphabet and not to entire words, it can be used to spell out words in any language that uses the same alphabet; so it is not tied to any one language in particular, and to that extent, it is analogous to other letter-encodings, such as Morse code, or Semaphore.  The Rochester Method relies heavily on fingerspelling, but it is slow and has mostly fallen out of favor.   Hybrid methods use a mixture of aural/oral methods as well as some visible indicators such as hand shapes in order to communicate in the standard spoken language by making parts of it visible to those with hearing loss.According to Goldin-Meadow, reading requires two essential abilities: familiarity with a language and understanding the mapping between that language and the written word. However, reading is possible if deaf children learn ASL. Once they have acquired ASL, deaf children learn how to map between sign language and print so that they can learn English. Several techniques are used to help bridge the gap between ASL and spoken language or the "translation process" such as sandwiching and chaining. Sandwiching consists of alternating between saying the word and signing it. Chaining consists of finger spelling a word, pointing to the spoken language version of the word and using pictorial support. Although chaining is not widely used, it creates an understanding between the visual spelling of a word and the sign language spelling of the word. This helps the child become bilingual in both ASL and spoken language. The deaf child's social context is crucial for nurturing his or her capacity to read. Research shows that deaf children born to deaf parents are usually better readers than deaf children born to hearing parents.  This is because deaf parents provide a strong social and emotional network and may immediately have access to the necessary resources for their child. Deaf parents already anticipate the needs of their child, having been through the same experience, as opposed to a hearing parent.  A cochlear implant is placed surgically inside the cochlea, which is the part of the inner ear that converts sound to neural signals. There is much debate regarding the linguistic conditions under which deaf children acquire spoken language via cochlear implantation. Some studies have concluded that long-term use of sign language impedes the development of spoken language and reading ability in deaf and hard of hearing children, and that using sign language is not at all advantageous, and can be detrimental to language development.    However, studies have found that sign language exposure actually facilitates the development of spoken language of Deaf children of Deaf parents who had exposure to sign language from birth. These children outperformed their deaf peers who were born to hearing parents following cochlear implantation.   Cochlear implants have been the subject of a heated debate between those that believe deaf children should receive the implants and those that do not. Members of the Deaf Community believe this is an important ethical problem. They strongly advocate that sign language is their first or native language just as any other spoken language is for a hearing person. They do not see deafness as a deficiency in any way, but rather a normal human trait amongst a variety of different ones. One issue on the ethical perspective of implantation is the possible side effects that may present themselves after surgery (the body may physically reject the implant; for some reason, there may not be any benefit, or very little gained; the internal component may need to be replaced causing the need for another surgery), even in some cases lessening listening capabilities, losing residual hearing or hearing sounds differently. While the surgery presents one positive solution, these side effects are not often taken into account but are significant and need to be afforded more attention. However, complications from cochlear implant surgery is a rare event, with some centers showing less than a three percent failure rate."Cochlear Implant Failure Rate Generally Low".  Early exposure to language facilitates language acquisition, regardless of whether or not that exposure is native or non-native, as well as many other domains of development, such as cognitive development, including executive functioning skills. Executive functioning skills are extremely important, as these are the skills that guide learning and behavior . These skills include self-regulation, inhibition, emotional control, working memory, and planning and organization, which contribute to overall social, emotional and academic development for children. Early access to a language, such as sign language, from birth supports the development of these cognitive skills and abilities in Deaf and hard of hearing children, and supports their development in this area . However, late exposure to language and delayed language acquisition can inhibit or delay the cognitive development of deaf and hard of hearing children, and impact these skills. This late exposure to language, or lack thereof, can be defined as language deprivation (see Language deprivation in deaf and hard of hearing children). This experience is the result of a lack of exposure to natural human language, whether that be spoken or signed language, during the critical language period . Approximately 90% of Deaf children are born to hearing parents, and 95% of those Deaf children experience language deprivation to some degree . Language Deprivation has been found to impair deaf children’s cognitive development, specifically their executive functioning skills, and working memory, causing deficits in critical executive functioning skills and overall cognitive development. . It is not deafness that causes these deficits, but late language acquisition that influences the cognitive development and abilities of deaf people.  Having an acquired language means an individual has had full access to at least one spoken or signed language.Typically, if a person has had this full access to language and has been able to acquire it, then being able to enter into a realm of social and emotional becomes plausible. Being able to communicate using is critical for those still developing their social skills . There is also evidence to suggest that language acquisition can play a critical role in developing Theory of Mind, or developing the understanding of false beliefs in language . For children who have been deprived of this access or have not yet fully acquired a language, social development can be hindered, which in turn can affect one’s emotional development as well.The lack of socialization can significantly impact a child’s emotional well-being. A child’s first experience with social communication typically begins at home, but deaf and hard of hearing children in particular who are born to hearing parents tend to struggle with this interaction, due to the fact that they are a “minority in their own family" . Parents who have a Deaf child typically do not know a signed language, the logistical problem can become how to give that child a full language. If deaf and hard of hearing children are not developing their social skills at home, by the time they enter school, they can be behind in this development. All of this can lead to struggles with proper emotional development. It can be hard on a child who was not given a language early to try and express their emotions appropriately. The problem is not with the deaf child, but instead, not giving a deaf or hard of hearing child the necessary language access from birth that other children receive . There are theories to suggest that language acquisition is a predictor of how a child can develop Theory of Mind and without a full language, this skill becomes null. Theory of Mind can be an indicator of social and cognitive development. Without language acquisition, Deaf children can become behind in Theory of Mind and the skills that coincide, which can lead to further social and emotional delays.  Second language acquisition is also highly affected by early language exposure . More exposure in an accessible language leads to better performance in the second language upon entering school . Providing deaf and hard of hearing children with the most language exposure possible from birth promotes both first and second language acquisition. This means giving students the opportunity to develop language at home and in social environments early on supports the child's language acquisition in American Sign Language as well as printed English . There is extensive research regarding the correlation between proficiency in ASL and proficiency in English literacy skills .[verification needed]. Deaf students with higher ASL proficiency tend to have higher English reading and writing scores . There is also research to support that the development of a second language also improves proficiency in the student's first language  According to Hrastinski & Wilbur (2016), American Sign Language proficiency is the single most contributing factor to Deaf student’s academic achievement, particularly in reading literacy and math. . Deaf and hard of hearing children who have higher levels of American Sign Language proficiency and those who have higher proficiency in a second language (e.g., English) are those who were exposed to American Sign Language during the critical period of language.  