Language processing refers to the way humans use words to communicate ideas and feelings, and how such communications are processed and understood. Thus it is how the brain creates and understands language. Most recent theories consider that this process is carried out entirely by and inside the brain; however, environmental factors play a role in the development of language processing as well. This is considered one of the most characteristic abilities of the human species. However very little is known about it and there is huge scope for research on it. Most of the knowledge acquired to date on the subject has come from patients who have suffered some type of significant head injury, whether external (wounds, bullets) or internal (strokes, tumors, degenerative diseases). Studies have shown that most of the language processing functions are carried out in the cerebral cortex. The essential function of the cortical language areas is symbolic representation. Even though language exists in different forms, all of them are based on symbolic representation.  Much of the language function is processed in several association areas, and there are two well-identified areas that are considered vital for human communication: Wernicke's area and Broca's area. These areas are usually located in the dominant hemisphere (the left hemisphere in 97% of people) and are considered the most important areas for language processing. This is why language is considered a localized and lateralized function.  However, the non-dominant hemisphere also participates in this cognitive function, and there is ongoing debate on the level of participation of the less-dominant areas.  The non-dominant hemisphere may be particularly involved in processing the prosody of spoken language. Other factors are believed to be relevant to language processing and verbal fluency, such as cortical thickness, participation of prefrontal areas of the cortex, and communication between right and left hemispheres. Wernicke's area is classically located in the posterior section of the superior temporal gyrus of the dominant hemisphere (Brodmann area 22), with some branches extending around the posterior section of the lateral sulcus, in the parietal lobe.  Wernicke's area is located between the auditory cortex and the visual cortex. The former is located in the transverse temporal gyrus (Brodmann areas 41 and 42), in the temporal lobe, while the latter is located in the posterior section of the occipital lobe (Brodmann areas 17, 18 and 19).  While the dominant hemisphere is in charge of most of language comprehension, recent studies have demonstrated that the non-dominant (right hemisphere in 97% of people) homologous area participates in the comprehension of ambiguous words, whether they are written or heard.  Receptive speech has traditionally been associated with Wernicke's area of the posterior superior temporal gyrus (STG) and surrounding areas. Current models of speech perception include greater Wernicke's area, but also implicate a "dorsal" stream that includes regions also involved in speech motor processing.  First identified by Carl Wernicke in 1874, its main function is the comprehension of language and the ability to communicate coherent ideas, whether the language is vocal, written, or signed.  Broca's area is usually formed by the pars triangularis and the pars opercularis of the inferior frontal gyrus (Brodmann areas 44 and 45). It follows Wernicke's area, and as such they both are usually located in the left hemisphere of the brain.  Broca's area is involved mostly in the production of speech. Given its proximity to the motor cortex, neurons from Broca's area send signals to the larynx, tongue and mouth motor areas, which in turn send the signals to the corresponding muscles, thus allowing the creation of sounds.  A recent analysis of the specific roles of these sections of the left inferior frontal gyrus in verbal fluency indicates that Brodmann area 44 (pars opercularis) may subserve phonological fluency, whereas the Brodmann area 45 (pars triangularis) may be more involved in semantic fluency.  Further analysis shows that Broca's area may have less involvement with information for producing individual words, but, instead, Broca's area is shown to coordinate language processing information for speech production on a greater scale.  The arcuate fasciculus is the area of the brain between Wernicke's area and Broca's area that connects the two through bundles of nerve fibers. This portion of the brain serves as a transit center between the two areas dealing most largely with speech and communication.  Recent studies have shown that the rate of increase in raw vocabulary fluency was positively correlated with the rate of cortical thinning. In other words, greater performance improvements were associated with greater thinning. This is more evident in left hemisphere regions, including the left lateral dorsal frontal and left lateral parietal regions: the usual locations of Broca's area and Wernicke's area, respectively.  After Sowell's studies, it was hypothesized that increased performance on the verbal fluency test would correlate with decreased cortical thickness in regions that have been associated with language: the middle and superior temporal cortex, the temporal–parietal junction, and inferior and middle frontal cortex. Additionally, other areas related to sustained attention for executive tasks were also expected to be affected by cortical thinning.  One theory for the relation between cortical thinning and improved language fluency is the effect that synaptic pruning has in signaling between neurons. If cortical thinning reflects synaptic pruning, then pruning may occur relatively early for language-based abilities. The functional benefit would be a tightly honed neural system that is impervious to "neural interference", avoiding undesired signals running through the neurons which could possibly worsen verbal fluency.  The strongest correlations between language fluency and cortical thicknesses were found in the temporal lobe and temporal–parietal junction. Significant correlations were also found in the auditory cortex, the somatosensory cortex related to the organs responsible for speech (lips, mouth), and frontal and parietal regions related to attention and performance monitoring. The frontal and parietal regions are also evident in the right hemisphere.  Environmental effects, such as social and economic factors and quality of input, affect the development of language processing. Differences in family socioeconomic status affects language development, leading to those from high-socioeconomic-status families having greater efficiency with language processing. These differences in language processing are evident in children as young as 18 months.  Children from lower socioeconomic statuses who receive less cognitive stimulation from their environment are at a greater disadvantage with language processing.  Research on bilingual speakers shows that information about both languages is activated in the brain even when a speaker is only using one language. Some research shows that, because bilingual speakers access linguistic information in their brain differently from monolingual speakers, they have an advantage in language processing, and they outperform monolingual speakers in reaction times for language processing and then producing relevant language in certain tasks.  However, other studies have found that this may not be applicable to all bilinguals.  The use of child-directed speech affects this development in children. Those who are exposed to a greater quantity of child-directed speech develop greater proficiency with language processing.  Acoustic stimuli are received by the auditive organ and are converted to bioelectric signals on the organ of Corti. These electric impulses are then transported through scarpa's ganglion (vestibulocochlear nerve) to the primary auditory cortex, on both hemispheres. Each hemisphere treats it differently, nevertheless: while the left side recognizes distinctive parts such as phonemes, the right side takes over prosodic characteristics and melodic information. The signal is then transported to Wernicke's area on the left hemisphere (the information that was being processed on the right hemisphere is able to cross through inter-hemispheric axons), where the already noted analysis takes part. During speech comprehension, activations are focused in and around Wernicke's area. A large body of evidence supports a role for the posterior superior temporal gyrus in acoustic–phonetic aspects of speech processing, whereas more ventral sites such as the posterior middle temporal gyrus (pMTG) are thought to play a higher linguistic role linking the auditory word form to broadly distributed semantic knowledge.  Also, the pMTG site shows significant activation during the semantic association interval of the verb generation and picture naming tasks, in contrast to the pSTG sites that remain at or below baseline levels during this interval. This is consistent with a greater lexical–semantic role for pMTG relative to a more acoustic–phonetic role for pSTG.  From Wernicke's area, the signal is taken to Broca's area through the arcuate fasciculus. Speech production activations begin prior to verbal response in the peri-Rolandic cortices (pre- and postcentral gyri). The role of ventral peri-Rolandic cortices in speech motor functions has long been appreciated (Broca's area). The superior portion of the ventral premotor cortex also exhibited auditory responses preferential to speech stimuli and are part of the dorsal stream.  Involvement of Wernicke's area in speech production has been suggested and recent studies document the participation of traditional Wernicke's area (mid-to posterior superior temporal gyrus) only in post-response auditory feedback, while demonstrating a clear pre-response activation from the nearby temporal-parietal junction (TPJ).  It is believed that the common route to speech production is through verbal and phonological working memory using the same dorsal stream areas (temporal-parietal junction, sPMv)  implicated in speech perception and phonological working memory. The observed pre-response activations at these dorsal stream sites are suggested to subserve phonological encoding and its translation to the articulatory score for speech. Post-response Wernicke's activations, on the other hand, are involved strictly in auditory self-monitoring.  Several authors support a  model in which the route to speech production runs essentially in reverse of speech perception, as in going from conceptual level to word form to phonological representation.  Early auditory processing and word recognition take place in inferior temporal areas ("what" pathway), where the signal arrives from the primary and secondary visual cortices. The representation of the object in the "what" pathway and nearby inferior temporal areas itself constitutes a major aspect of the conceptual–semantic representation. Additional semantic and syntactic associations are also activated, and during this interval of highly variable duration (depending on the subject, the difficulty of the current object, etc.), the word to be spoken is selected. This involves some of the same sites – prefrontal cortex (PFC), supramarginal gyrus (SMG), and other association areas – involved in the semantic selection stage of verb generation.  The acquired language disorders that are associated to brain activity are called aphasias. Depending on the location of the damage, the aphasias can present several differences. The aphasias listed below are examples of acute aphasias which can result from  brain injury or stroke . 