Junction Grammar is a descriptive model of language developed during the 1960s by Dr. Eldon G. Lytle (1936–2010) . Junction Grammar is based on the premise that the meaning of language can be described and precisely codified by the way language elements are joined together. The model was used during the 1960s and 1970s in the attempt to create a functional computer-assisted translation system. It has also been used for linguistic analysis in the language instruction field. Early generative grammars dealt with language from a syntactic perspective, i.e. as the problem presented by the task of creating  rules able to combine words into well-formed (i.e., grammatical) sentences.  The rules used by these grammars were referred to as phrase-structure rules (P-rules). It was soon apparent, however, that a generative component composed solely of P-rules could not generate a wide variety of commonly occurring sentence types. In response to this dilemma, we find Harris proposing an explanation: Some of the cruces in descriptive linguistics have been due to the search for a constituent analysis in sentence types where this does not exist because the sentences are transformationally derived from each other [boldface added] Chomsky’s model of syntax - transformational grammar -picked up on this line of reasoning and added a supplementary set of transformations (T-rules). T-rules effected combinations and permutations of words in step-wise fashion to fill in structural gaps where P-rules alone could not generate the sentences which Harris had pointed out as problems. The structural forms generated by P-rules alone were said to constitute ‘deep structure.’ ‘Surface structure’ was then derived transformationally by T-rules from the ‘kernel’ structures first generated by the operation of P-rules. In this way, Chomsky proposed to generate an infinite number of sentences using finite means (the closed sets of P-rules and T-rules). Syntax-based models of this vintage set semantics and phonology apart as linguistic processes to be approached separately. Enter from the sidelines under these circumstances  junction grammar (JG),  a model of natural language created by Eldon Lytle in the late ‘60s and early ‘70s.  Junction grammar did not propose an amendment to Chomsky’s model of syntax, but purported to eliminate the need for transformations altogether through theoretical innovation and a novel design for generative grammars. Innovations fundamental to the new approach rejected common-place reliance on existing mathematics and formal language theory as tools for linguistic modeling and description in deference to the intuition of more fundamental structuring in the body and in natural language itself which appeared to provide a universal base for linguistic description - not only for natural language but also for the synthetic notation systems employed at the time for linguistic description. Implementation of the novelties in question entailed: In sum, the junction grammar model of language (1) moved the base into a sub-verbal semantic domain, (2) added universally relevant linguistic operators to generation rules - thus, for example, solving the quandary of how to handle 'conjunction' - (3) incorporated auxiliary  'tracts' together with specialized data types for voice, audition, etc., and (4) added coding grammars to physically interface between tracts. The right-left, top-down representational format which forced everything into one big tree was dispensed with in favor of an ensemble of interfacing representations which employed as many data-specific descriptions as necessary to capture the functionality of the diverse neurobiological manifestations of linguistic behavior being dealt with. Because target structuring was generable directly by the powerful J-rule base component and its array of linguistic operators, structure-oriented transformations required to combine kernel sentences and/or otherwise manipulate constituent structure were no longer required. Transformations formulated to generate correct word order and otherwise massage surface strings were supplanted by coding algorithms/grammars in the JG model.   It may be said by way of general comparison that, whereas Chomsky's model of syntax was by design derivative (speaking of its roots in existing forms of notation), derivational, and manipulative, the JG model was seminal (speaking of its formal novelty), modular, and  transpositional. Despite polar differences, however, Chomsky's objective of generating an infinite number of sentences with finite means, remained firmly intact in JG, as did the presumption of the fundamental innateness of natural language in the normal speaker/hearer. The base/junction rules (J-rules) of junction grammars are a set of algebraic formulas which generate for natural language what is akin to the Periodic Table of elements in chemistry, namely, an enumeration of well-formed linguistic structures  sometimes referred to as the Periodic Chart of Constituent structures (PCCS).  J-rules generate composite structures consisting of the labeled operands entering into them plus the relations established by operators, and assign a category to the composite produced, to wit: X ∘ Y ≐ Z. Composites thus generated become potential operands for subsequent operations. The resulting algebra may be represented in string form (e.g., infix, postfix, reverse polish) or graphed as a branching diagram (J-tree). The universal operators utilized by these rules are subjunction (*), conjunction (&), and adjunction (+), plus subtypes required under particular circumstances, e.g., restrictive (.*) versus non-restrictive (=*=) under subjunction. Expressed in more familiar terms, subjunction joins modifiers and complements to their heads, conjunction bonds constituents of homogeneous category which are in some respect similar, and adjunction  attaches relations and processes to their operands to form predicates, statements, and relational phrases. Supplemental operators effect the requirements of data management in mental modeling and conversational settings, corresponding in large part to the conventional classification of deixis.  The operands of the base are drawn from a dictionary of sememes (meaningful concepts) which are by definition non-lexical in JG and may be plausibly viewed as electromagnetic signatures in their neurobiological setting  arising in connection with the formation of the mental models which provide the content and sensory linkages for their meanings. While the link between signified and signifier (as per Saussure) may be separately represented in a junction grammar, the interfacing between J-rule structuring and the coding extant in other components of the model is provided by context-sensitive coding grammars formulated as algorithms in an appropriate pattern matching language. For example, JG incorporates a lexical coding grammar consisting of lexical rules (L-rules) which encodes unordered sememic structuring as ordered lexical strings in a separate coding space.  A subsequent coding provides either the distinct patterning of the voice contour, or the formatting and punctuation of printed material. With the foregoing as a frame of reference, we draw renewed attention to significant differences between JG sentence analysis and conventional syntactic analysis. The more familiar syntax approach analyzes phrases and sentences in terms of outward ('surface') appearance, i.e. in terms of the words which they contain and how intuition groups them. Structural diagrams reflecting this method strive to depict constituent clusters in the word stream supplemented by labels, perhaps, or other information of focal interest to the analyst - some of it perhaps semantic. A change in word order requires that the diagram be changed. In contrast, the JG approach, while taking note of the words, looks beyond them to the base constructions from which they have presumably been encoded, concentrating all the while on the semantic effects associated with the constituents and their structural nuances. JG diagrams (J-trees), therefore, are not directly representative of the word stream but, rather, of rational constructs in the neural mass having linkage with the words which we read or write. This means that a variety of structuring detail made explicit in J-trees is only implicit in the word stream. Conversely, it means that certain lexical detail made explicit in the word stream is only implicit in J-trees. For example, depending upon the ordering rules of the lexical coding grammar in play and the discourse context of the sentence - the same J-tree  may yield alternative word orders in the lexical coding space. The overall effect - as previously noted - is that, inasmuch as JG uses coding rather than derivation as a bridge between levels of representation, much that models of syntax have been preoccupied with in deriving surface structure from deep structure (movement, deletion, insertion, etc.) is taken over in JG by coding operations. The first junction grammar was worked out by Eldon Lytle in connection with his Ph.D. dissertation during the late ‘60s,  in which he constructed such a grammar for the analysis of structural derivation in Russian. That grammar relegated the data to four levels of representation, corresponding to: Lytle employed one of the junction operators (subjunction) as a formal device to impose the properties of a governing category upon existing structure to obtain ‘derived’ forms (e.g., ‘transform-ation’ - Noun * Verb). Early literature on JG was published in Junction Theory and Application, the journal of the BYU Translation Sciences Institute (TSI), and/or the proceedings of the University’s Annual Linguistic Symposium.  More widely distributed overviews and analyses of junction theory first appeared in monograph form under Mouton’s Janua Linguarum Series,  followed by papers and research reports presented at LACUS forum proceedings  and linguistic conferences abroad.  Meanwhile, others tested the model for applicability to natural languages distanced from English.  The latter studies applied junction analysis to particular languages of diverse families, including Finnish,  Samoan,  Korean,  Japanese,   and Russian.  Chinese, French, German, Spanish, Portuguese were added to this list in due course (see below) . Following these studies, it was concluded that the J-rules comprising the syntacto-semantic base of the model proffered a pool of structural possibilities from which all natural languages draw, but that none necessarily uses them all nor the same subset. During the early ‘70s, at the urging and under the auspices of the Department of Defense, Lytle and a team of colleagues conducted research at  BYU in computer-assisted, human-interactive translation in which junction grammars were subjected to formalization    and applied to the problem of English-Russian translation. When positive results evinced proof of concept and a software prototype, funds from the private sector were invested to develop and test a one-to-many system based on the same translation model in expanded form - in particular, translations were synthesized from J-trees of English obtained via human interaction into Russian, Spanish, French, German, Portuguese, and Chinese.   Just prior to his inauguration as president, Gerald Ford and an entourage of VIPS visited the development site to receive a briefing on the concept and progress of the work. At the conclusion of this  endeavor, an alpha model of the software translated a book submitted for test purposes and yielded translations in the cited target languages. While significant post-editing was required, suggesting - among other improvements -  that a second, language-specific interaction may well improve the design, the utility of computers as a useful translation aid, both in standardizing the use of terminology and expediting the overall translation process had been demonstrated.  JG adherents soon observed that the structural particulars of adjunction, conjunction, and subjunction are relevant beyond conventional linguistic structuring. More specifically, they lend themselves to such diverse structural scenarios as spousal interaction, departmental interaction in institutions, and a host of other real-world phenomena. In response to this observation, Lytle developed a method of phonological representation based on phonemic operands and junction operators.   This method of representation was subsequently utilized as the basis for synthesizing speech contours which reflected the structure of the source text.   JG proved to be classroom friendly, not only because its base structures were more intuitive, comprehensive, and explicit than traditional forms of diagramming, but also because their connection to overt forms of language were straightforward. Students quickly picked up on the challenge presented by the structural predictions of the PCCS and undertook to assist in verifying them. Among the memorable sentence types brought forward in class to challenge instructors and the Chart were: Studies were conducted to determine whether exposure to the JG method of diagramming was useful as a point of reference in teaching/learning foreign languages. Olson and Tuttle found that the answer was affirmative.   Subsequent to his experience with computer-assisted translation and voice synthesis, Lytle undertook the development of JG-based educational software in the private sector. To facilitate his objectives he designed what is referred to as ‘JG Markup Notation’ and created a pattern matching language (JGPL) to complement it.  This endeavor relied on the escalating power of micro-computers to field JG-powered applications able to provide constructive feedback to student writers and their teachers in a writing-lab context.  The project culminated in a successful field test in a district of the public school system  and ultimately a study conducted jointly with the Educational Testing Service (ETS) to evaluate the potential of such software to holistically score student written products. The joint conclusion: ...computer analysis of student ways can provide a level of detail in feedback to students, teachers, and others that is not possible using human readers alone.  This kind of feedback has important implications for instruction in English composition.  Moreover, computer analysis can provide detailed feedback on many written products, even lengthy ones; a teacher of English will normally provide detailed feedback on only a few brief essays. In more recent research, Millett has independently demonstrated the ability of the same JG-based software to evaluate the writing of ESL students of mixed nationalities.  Owing to its demonstrated potential for educational assessment, overtures have been made to declare JGPL and its associated software applications - The WordMap Writing-Aids Software Ensemble - ‘open source’ so that it may serve as an expandable and adaptable public educational resource. This proposal is presently 'under advisement.' Meanwhile, to test the utility of JG-related writing assessment in an internet environment, the JGPL analysis engine has been made available free of charge for experimentation in an online writing-lab setting.  This tree was constructed in a tutorial setting equipped with experimental software for computer-aided JG diagramming. Note the explicit specification of junction operators on the squiggly lines connecting the node labels. This is one aspect of JG linguistic description which sets it apart from other models and from which its name derives. Conventional branching diagrams may also be used, but in any case the junction operator must be written between the nodes serving as its operands. Junction theory holds that linguistic structures written without junctions have no more meaning/substance than concatenations of algebraic operands written without any indication of the operations to be performed with them. Because of its algebraic format - and owing to its use of non-verbal formatives -  JG base description has of late been dubbed MindMath. Some theoreticians have suggested that it would be productive to merge certain features of junction grammar with other models. Millett and Lonsdale, in fact, have proposed an expansion of Tree Adjoining Grammar (TAG) to create junction trees.  In planning for systematic expansion of the JG model of language, ‘elevator shafts’ were included in its original layout for the eventual incorporation of modules to deal with such phenomena as sensation, cognition, mental modeling, and communication - all of these being considered integral to the operation of language in its natural setting. Inasmuch as the addition of modules entails addition of data types and their dictionaries, reference was made in the literature to such future expansion as a function of `orders of specificity,' with each module or significant rule refinement ascending to a higher order, as it were.  JG had - through its use of non-verbal data types - tacitly implemented Whorf’s expanded definition of language from its inception. To wit: ...The linguistic order embraces all symbolism, all symbolic process, all process of reference and of logic... At that point where formal development of the module for Level 1 (the `real’ world) was contemplated, it became apparent that JG was graduating from a model managing the connection between MIND and EXPRESSION as a matter of linkage between familiar and readily representable data types (e.g., between the sememic data of the ‘mind tract’ and those required for the 'vocal tract') ... to a model which must now also make explicit the connection between MIND and REALITY in a general way among a profusion of data types systematically written upon by MIND in the ‘cold and dreary’ world itself. The fact of the matter was that even though Level 1 had been occupying space in the schematic from its inception, with the exception of voice synthesis, no ‘order of specificity’ had as yet been implemented in JG to formalize the linkage between sememic data and forms of physical reality. That the linkage existed was simply a matter of observation: Each time an instruction was given and carried out, for example, the structuring specified by the instruction was realized in the physical media to which the terms of the language referred. Ditto for the relation between recipes and cakes, blueprints and houses, constitutions and governments, etc. In each case, the linguistic relations became real, with the referents to which they applied representing themselves - a circumstance referred to in the parlance of JG as reflexive symbolism. As the ramifications of this scenario were examined, it became apparent that the emergent ‘JG Upgrade Model’ was now making direct contact with Benjamin Whorf’s full conceptual model, which saw structuring in the world at large as a physical extension of the language in MIND, while writing and speech - by way of comparison -  were rational extensions of language in MIND. To quote Whorf:  All that I have to say on the subject that may be new is of the PREMONITION IN LANGUAGE of the unknown, vaster world - that world of which the physical is but a surface or skin, and yet which we ARE IN, and BELONG TO ... Speech is the best show man puts on ... But we suspect the watching Gods perceive that the order in which his amazing set of tricks builds up to a great climax has been stolen - from the  Universe!   Here then was the explanation for the relevance of JG’s fundamental constituent relations to external relationships and the reason why Lytle had been able to represent articulatory structuring with junction operations. There is indeed a linguistic linkage between MIND and REALITY ... and hence, theoretically, a 'linguistic' description for every structured phenomenon. This, perhaps, portends the ultimate ascent of linguistic science to a level of prominence previously envisioned only by Whorf.  (We resume discussion of this eventuality below.) To formally implement the linkage in question as a feature of the JG Upgrade Model, it was necessary to add notational symbolism able to describe the nature of the coding which transpires at the MIND-REALITY interface. To this end, symbols were introduced to signify the mental processes which are used to create instruction and to apply it, as well as the act of describing such processes. To this end, corresponding operators were added to the JG inventory for: Other symbolism was incorporated to signify authorship (  Kx  ), as well as the language being employed (Lx ) vis-a-vis the language continuum (the global blend of ideolects,  dialects, and languages), as well as the data types operative as media to be structured in the physical domain  (Mx).  These notational addenda, when systematically organized and augmented with other pertinent formal devices, enable the linguist to write expressions for such diverse activities as mental modeling, conversation, putting one’s words into action, and use of the empirical method for discovery. Inasmuch as the system of classical junction rules can be derived directly from the new, more comprehensive symbolism, it is clear that the enhancements in question are a natural extension of the original model. 