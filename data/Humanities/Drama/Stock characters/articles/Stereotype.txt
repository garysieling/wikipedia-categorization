In social psychology, a stereotype is an over-generalized belief about a particular category of people.  Stereotypes are generalized because one assumes that the stereotype is true for each individual person in the category.  While such generalizations may be useful when making quick decisions, they may be erroneous when applied to particular individuals.  Stereotypes encourage prejudice  and may arise for a number of reasons. Explicit stereotypes are those people are willing to verbalize and admit to other individuals. Implicit stereotypes are those that lay on individuals' unconsciousness, that they have no control or awareness of.  In social psychology, a stereotype is any thought widely adopted about specific types of individuals or certain ways of behaving intended to represent the entire group of those individuals or behaviors as a whole.   These thoughts or beliefs may or may not accurately reflect reality.   Within psychology and across other disciplines, different conceptualizations and theories of stereotyping exist, at times sharing commonalities, as well as containing contradictory elements. The term stereotype comes from the French adjective stéréotype and derives from the Greek words στερεός (stereos), "firm, solid"  and τύπος (typos), impression,  hence "solid impression on one or more idea/theory." The term comes from the printing trade and was first adopted in 1798 by Firmin Didot to describe a printing plate that duplicated any typography. The duplicate printing plate, or the stereotype, is used for printing instead of the original. Outside of printing, the first reference to "stereotype" was in 1850, as a noun that meant image perpetuated without change.  However, it was not until 1922 that "stereotype" was first used in the modern psychological sense by American journalist Walter Lippmann in his work Public Opinion.  Stereotypes, prejudice, and discrimination   are understood as related but different concepts.     Stereotypes are regarded as the most cognitive component and often occurs without conscious awareness, whereas prejudice is the affective component of stereotyping and discrimination is one of the behavioral components of prejudicial reactions.    In this tripartite view of intergroup attitudes, stereotypes reflect expectations and beliefs about the characteristics of members of groups perceived as different from one's own, prejudice represents the emotional response, and discrimination refers to actions.   Although related, the three concepts can exist independently of each other.   According to Daniel Katz and Kenneth Braly, stereotyping leads to racial prejudice when people emotionally react to the name of a group, ascribe characteristics to members of that group, and then evaluate those characteristics.  Possible prejudicial effects of stereotypes  are: Stereotype content refers to the attributes that people think characterize a group. Studies of stereotype content examine what people think of others, rather than the reasons and mechanisms involved in stereotyping.  Early theories of stereotype content proposed by social psychologists such as Gordon Allport assumed that stereotypes of outgroups reflected uniform antipathy.   For instance, Katz and Braly argued in their classic 1933 study that ethnic stereotypes were uniformly negative.  By contrast, a newer model of stereotype content theorizes that stereotypes are frequently ambivalent and vary along two dimensions: warmth and competence. Warmth and competence are respectively predicted by lack of competition and status. Groups that do not compete with the in-group for the same resources (e.g., college space) are perceived as warm, whereas high-status (e.g., economically or educationally successful) groups are considered competent. The groups within each of the four combinations of high and low levels of warmth and competence elicit distinct emotions.  The model explains the phenomenon that some out-groups are admired but disliked, whereas others are liked but disrespected. This model was empirically tested on a variety of national and international samples and was found to reliably predict stereotype content.   Early studies suggested that stereotypes were only used by rigid, repressed, and authoritarian people. This idea has been refuted by contemporary studies that suggest the ubiquity of stereotypes and  it was suggested to regard stereotypes  as collective group beliefs, meaning that people who belong to the same social group share the same set of stereotypes.  Modern research asserts that full understanding of stereotypes requires considering them from two complementary perspectives: as shared within a particular culture/subculture and as formed in the mind of an individual person.  Stereotyping can serve cognitive functions on an interpersonal level, and social functions on an intergroup level.   For stereotyping to function on an intergroup level (see social identity approaches: social identity theory and self-categorization theory), an individual must see themselves as part of a group and being part of that group must also be salient for the individual.  Craig McGarty, Russell Spears, and Vincent Y. Yzerbyt (2002) argued that the cognitive functions of stereotyping are best understood in relation to its social functions, and vice versa.  Stereotypes can help make sense of the world. They are a form of categorization that helps to simplify and systematize information. Thus, information is more easily identified, recalled, predicted, and reacted to.  Stereotypes are categories of objects or people. Between stereotypes, objects or people are as different from each other as possible.  Within stereotypes, objects or people are as similar to each other as possible.  Gordon Allport has suggested possible answers to why people find it easier to understand categorized information.  First, people can consult a category to identify response patterns. Second, categorized information is more specific than non-categorized information, as categorization accentuates properties that are shared by all members of a group. Third, people can readily describe objects in a category because objects in the same category have distinct characteristics. Finally, people can take for granted the characteristics of a particular category because the category itself may be an arbitrary grouping. A complementary perspective theorizes how stereotypes function as time- and energy-savers that allow people to act more efficiently.  Yet another perspective suggests that stereotypes are people's biased perceptions of their social contexts.  In this view, people use stereotypes as shortcuts to make sense of their social contexts, and this makes a person's task of understanding his or her world less cognitively demanding.  In the following situations, the overarching purpose of stereotyping is for people to put their collective self (their in-group membership) in a positive light:  As mentioned previously, stereotypes can be used to explain social events.   Henri Tajfel  described his observations of how some people found that the anti-Semitic contents of The Protocols of the Elders of Zion only made sense if Jews have certain characteristics. Therefore, according to Tajfel,  Jews were stereotyped as being evil and yearning for world domination to match the anti-Semitic ‘facts’ as presented in The Protocols of the Elders of Zion. People create stereotypes of an outgroup to justify the actions that their in-group has committed (or plans to commit) towards that outgroup.    For example, according to Tajfel,  Europeans stereotyped Turkish, Indian, and Chinese people as being incapable of achieving financial advances without European help. This stereotype was used to justify European colonialism in Turkey, India, and China. An assumption is that people want their ingroup to have a positive image relative to outgroups, and so people want to differentiate their ingroup from relevant outgroups in a desirable way.  If an outgroup does not affect the ingroup’s image, then from an image preservation point of view, there is no point for the ingroup to be positively distinct from that outgroup.  People can actively create certain images for relevant outgroups by stereotyping. People do so when they see that their ingroup is no longer as clearly and/or as positively differentiated from relevant outgroups, and they want to restore the intergroup differentiation to a state that favours the ingroup.   Stereotypes can emphasize a person’s group membership in two steps: Stereotypes emphasize the person’s similarities with ingroup members on relevant dimensions, and also the person’s differences from outgroup members on relevant dimensions.  People change the stereotype of their ingroups and outgroups to suit context.  Once an outgroup treats an ingroup member badly, they are more drawn to the members of their own group.  This can be seen as members with in a group are able to relate to each other though a stereotype because of identical situations. A person can embrace a stereotype to avoid humiliation such as failing a task and blaming it on a stereotype.  Stereotypes are an indicator of ingroup consensus.  When there are intragroup disagreements over stereotypes of the ingroup and/or outgroups, ingroup members take collective action to prevent other ingroup members from diverging from each other.  John C. Turner proposed in 1987  that if ingroup members disagree on an outgroup stereotype, then one of three possible collective actions follow: First, ingroup members may negotiate with each other and conclude that they have different outgroup stereotypes because they are stereotyping different subgroups of an outgroup (e.g., Russian gymnasts versus Russian boxers). Second, ingroup members may negotiate with each other, but conclude that they are disagreeing because of categorical differences amongst themselves. Accordingly, in this context, it is better to categorise ingroup members under different categories (e.g., Democrats versus Republican) than under a shared category (e.g., American). Finally, ingroup members may influence each other to arrive at a common outgroup stereotype. Different disciplines give different accounts of how stereotypes develop: Psychologists may focus on an individual's experience with groups, patterns of communication about those groups, and intergroup conflict. As for sociologists, they may focus on the relations among different groups in a social structure. They suggest that stereotypes are the result of conflict, poor parenting, and inadequate mental and emotional development. Once stereotypes have formed, there are two main factors that explain their persistence. First, the cognitive effects of schematic processing (see schema) make it so that when a member of a group behaves as we expect, the behavior confirms and even strengthens existing stereotypes. Second, the affective or emotional aspects of prejudice render logical arguments against stereotypes ineffective in countering the power of emotional responses.  Correspondence bias refers to the tendency to ascribe a person's behavior to disposition or personality, and to underestimate the extent to which situational factors elicited the behavior. Correspondence bias can play an important role in stereotype formation.  For example, in a study by Roguer and Yzerbyt (1999) participants watched a video showing students who were randomly instructed to find arguments either for or against euthanasia. The students that argued in favor of euthanasia came from the same law department or from different departments. Results showed that participants attributed the students' responses to their attitudes although it had been made clear in the video that students had no choice about their position. Participants reported that group membership, i.e., the department that the students belonged to, affected the students' opinions about euthanasia. Law students were perceived to be more in favor of euthanasia than students from different departments despite the fact that a pretest had revealed that subjects had no preexisting expectations about attitudes toward euthanasia and the department that students belong to. The attribution error created the new stereotype that law students are more likely to support euthanasia.  Nier et al. (2012) found that people who tend to draw dispositional inferences from behavior and ignore situational constraints are more likely to stereotype low-status groups as incompetent and high-status groups as competent. Participants listened to descriptions of two fictitious groups of Pacific Islanders, one of which was described as being higher in status than the other. In a second study, subjects rated actual groups – the poor and wealthy, women and men – in the United States in terms of their competence. Subjects who scored high on the measure of correspondence bias stereotyped the poor, women, and the fictitious lower-status Pacific Islanders as incompetent whereas they stereotyped the wealthy, men, and the high-status Pacific Islanders as competent. The correspondence bias was a significant predictor of stereotyping even after controlling for other measures that have been linked to beliefs about low status groups, the just-world hypothesis and social dominance orientation.  Research has shown that stereotypes can develop based on a cognitive mechanism known as illusory correlation – an erroneous inference about the relationship between two events.    If two statistically infrequent events co-occur, observers overestimate the frequency of co-occurrence of these events. The underlying reason is that rare, infrequent events are distinctive and salient and, when paired, become even more so. The heightened salience results in more attention and more effective encoding, which strengthens the belief that the events are correlated.    In the intergroup context, illusory correlations lead people to misattribute rare behaviors or traits at higher rates to minority group members than to majority groups, even when both display the same proportion of the behaviors or traits. Black people, for instance, are a minority group in the United States and interaction with blacks is a relatively infrequent event for an average white American. Similarly, undesirable behavior (e.g. crime) is statistically less frequent than desirable behavior. Since both events "blackness" and "undesirable behavior" are distinctive in the sense that they are infrequent, the combination of the two leads observers to overestimate the rate of co-occurrence.  Similarly, in workplaces where women are underrepresented and negative behaviors such as errors occur less frequently than positive behaviors, women become more strongly associated with mistakes than men.  In a landmark study, David Hamilton and Richard Gifford (1976) examined the role of illusory correlation in stereotype formation. Subjects were instructed to read descriptions of behaviors performed by members of groups A and B. Negative behaviors outnumbered positive actions and group B was smaller than group A, making negative behaviors and membership in group B relatively infrequent and distinctive. Participants were then asked who had performed a set of actions: a person of group A or group B. Results showed that subjects overestimated the frequency with which both distinctive events, membership in group B and negative behavior, co-occurred, and evaluated group B more negatively. This despite the fact the proportion of positive to negative behaviors was equivalent for both groups and that there was no actual correlation between group membership and behaviors.  Although Hamilton and Gifford found a similar effect for positive behaviors as the infrequent events, a meta-analytic review of studies showed that illusory correlation effects are stronger when the infrequent, distinctive information is negative.  Hamilton and Gifford's distinctiveness-based explanation of stereotype formation was subsequently extended.  A 1994 study by McConnell, Sherman, and Hamilton found that people formed stereotypes based on information that was not distinctive at the time of presentation, but was considered distinctive at the time of judgement.  Once a person judges non-distinctive information in memory to be distinctive, that information is re-encoded and re-represented as if it had been distinctive when it was first processed.  One explanation for why stereotypes are shared is that they are the result of a common environment that stimulates people to react in the same way.  The problem with the ‘common environment’ explanation in general is that it does not explain how shared stereotypes can occur without direct stimuli.  Research since the 1930s suggested that people are highly similar with each other in how they describe different racial and national groups, although those people have no personal experience with the groups they are describing.  Another explanation says that people are socialised to adopt the same stereotypes.  Some psychologists believe that although stereotypes can be absorbed at any age, stereotypes are usually acquired in early childhood under the influence of parents, teachers, peers, and the media. If stereotypes are defined by social values, then stereotypes only change as per changes in social values.  The suggestion that stereotype content depend on social values reflects Walter Lippman's argument in his 1922 publication that stereotypes are rigid because they cannot be changed at will.  Studies emerging since the 1940s refuted the suggestion that stereotype contents cannot be changed at will. Those studies suggested that one group’s stereotype of another group would become more or less positive depending on whether their intergroup relationship had improved or degraded.    Intergroup events (e.g., World War Two, Persian Gulf conflict) often changed intergroup relationships. For example, after WWII, Black American students held a more negative stereotype of people from countries that were the United States’s WWII enemies.  If there are no changes to an intergroup relationship, then relevant stereotypes do not change.  According to a third explanation, shared stereotypes are neither caused by the coincidence of common stimuli, nor by socialisation. This explanation posits that stereotypes are shared because group members are motivated to behave in certain ways, and stereotypes reflect those behaviours.  It is important to note from this explanation that stereotypes are the consequence, not the cause, of intergroup relations. This explanation assumes that when it is important for people to acknowledge both their ingroup and outgroup, they will emphasise their difference from outgroup members, and their similarity to ingroup members.  The dual-process model of cognitive processing of stereotypes asserts that automatic activation of stereotypes is followed by a controlled processing stage, during which an individual may choose to disregard or ignore the stereotyped information that has been brought to mind.  A number of studies have found that stereotypes are activated automatically. Patricia Devine (1989), for example, suggested that stereotypes are automatically activated in the presence of a member (or some symbolic equivalent) of a stereotyped group and that the unintentional activation of the stereotype is equally strong for high- and low-prejudice persons. Words related to the cultural stereotype of blacks were presented subliminally. During an ostensibly unrelated impression-formation task, subjects read a paragraph describing a race-unspecified target person's behaviors and rated the target person on several trait scales. Results showed that participants who received a high proportion of racial words rated the target person in the story as significantly more hostile than participants who were presented with a lower proportion of words related to the stereotype. This effect held true for both high- and low-prejudice subjects (as measured by the Modern Racism Scale). Thus, the racial stereotype was activated even for low-prejudice individuals who did not personally endorse it.    Studies using alternative priming methods have shown that the activation of gender and age stereotypes can also be automatic.   Subsequent research suggested that the relation between category activation and stereotype activation was more complex.   Lepore and Brown (1997), for instance, noted that the words used in Devine's study were both neutral category labels (e.g., "Blacks") and stereotypic attributes (e.g., "lazy"). They argued that if only the neutral category labels were presented, people high and low in prejudice would respond differently. In a design similar to Devine's, Lepore and Brown primed the category of African-Americans using labels such as "blacks" and "West Indians" and then assessed the differential activation of the associated stereotype in the subsequent impression-formation task. They found that high-prejudice participants increased their ratings of the target person on the negative stereotypic dimensions and decreased them on the positive dimension whereas low-prejudice subjects tended in the opposite direction. The results suggest that the level of prejudice and stereotype endorsement affects people's judgements when the category – and not the stereotype per se – is primed.  Research has shown that people can be trained to activate counterstereotypic information and thereby reduce the automatic activation of negative stereotypes. In a study by Kawakami et al. (2000), for example, participants were presented with a category label and taught to respond "No" to stereotypic traits and "Yes" to nonstereotypic traits. After this training period, subjects showed reduced stereotype activation.   This effect is based on the learning of new and more positive stereotypes rather than the negation of already existing ones.  Empirical evidence suggests that stereotype activation can automatically influence social behavior.     For example, Bargh, Chen, and Burrows (1996) activated the stereotype of the elderly among half of their participants by administering a scrambled-sentence test where participants saw words related to age stereotypes. Subjects primed with the stereotype walked significantly more slowly than the control group (although the test did not include any words specifically referring to slowness), thus acting in a way that the stereotype suggests that elderly people will act. In another experiment, Bargh, Chen, and Burrows also found that because the stereotype about blacks includes the notion of aggression, subliminal exposure to black faces increased the likelihood that randomly selected white college students reacted with more aggression and hostility than participants who subconsciously viewed a white face.  Similarly, Correll et al. (2002) showed that activated stereotypes about blacks can influence people's behavior. In a series of experiments, black and white participants played a video game, in which a black or white person was shown holding a gun or a harmless object (e.g., a mobile phone). Participants had to decide as quickly as possible whether to shoot the target. When the target person was armed, both black and white participants were faster in deciding to shoot the target when he was black than when he was white. When the target was unarmed, the participants avoided shooting him more quickly when he was white. Time pressure made the shooter bias even more pronounced.  Stereotypes can be efficient shortcuts and sense-making tools. They can, however, keep people from processing new or unexpected information about each individual, thus biasing the impression formation process.  Early researchers believed that stereotypes were inaccurate representations of reality.  A series of pioneering studies in the 1930s found no empirical support for widely held racial stereotypes.  By the mid-1950s, Gordon Allport wrote that, "It is possible for a stereotype to grow in defiance of all evidence."  Research on the role of illusory correlations in the formation of stereotypes suggests that stereotypes can develop because of incorrect inferences about the relationship between two events (e.g., membership in a social group and bad or good attributes). This means that at least some stereotypes are inaccurate.     Empirical social science research shows that stereotypes are often accurate.   Jussim et al. reviewed four studies concerning racial and seven studies that examined gender stereotypes about demographic characteristics, academic achievement, personality and behavior. Based on that, the authors argued that some aspects of ethnic and gender stereotypes are accurate while stereotypes concerning political affiliation and nationality are much less accurate.  A study by Terracciano et al. also found that stereotypic beliefs about nationality do not reflect the actual personality traits of people from different cultures.  Attributive ambiguity refers to the uncertainty that members of stereotyped groups experience in interpreting the causes of others' behavior toward them. Stereotyped individuals who receive negative feedback can attribute it either to personal shortcomings, such as lack of ability or poor effort, or the evaluator's stereotypes and prejudice toward their social group. Alternatively, positive feedback can either be attributed to personal merit or discounted as a form of sympathy or pity.    Crocker et al. (1991) showed that when black participants were evaluated by a white person who was aware of their race, black subjects mistrusted the feedback, attributing negative feedback to the evaluator's stereotypes and positive feedback to the evaluator's desire to appear unbiased. When the black participants' race was unknown to the evaluator, they were more accepting of the feedback.  Attributional ambiguity has been shown to affect a person's self-esteem. When they receive positive evaluations, stereotyped individuals are uncertain of whether they really deserved their success and, consequently, they find it difficult to take credit for their achievements. In the case of negative feedback, ambiguity has been shown to have a protective effect on self-esteem as it allows people to assign blame to external causes. Some studies, however, have found that this effect only holds when stereotyped individuals can be absolutely certain that their negative outcomes are due to the evaluators's prejudice. If any room for uncertainty remains, stereotyped individuals tend to blame themselves.  Attributional ambiguity can also make it difficult to assess one's skills because performance-related evaluations are mistrusted or discounted. Moreover, it can lead to the belief that one's efforts are not directly linked to the outcomes, thereby depressing one's motivation to succeed.  Stereotype threat occurs when people are aware of a negative stereotype about their social group and experience anxiety or concern that they might confirm the stereotype.  Stereotype threat has been shown to undermine performance in a variety of domains.   Claude M. Steele and Joshua Aronson conducted the first experiments showing that stereotype threat can depress intellectual performance on standardized tests. In one study, they found that black college students performed worse than white students on a verbal test when the task was framed as a measure of intelligence. When it was not presented in that manner, the performance gap narrowed. Subsequent experiments showed that framing the test as diagnostic of intellectual ability made black students more aware of negative stereotypes about their group, which in turn impaired their performance.  Stereotype threat effects have been demonstrated for an array of social groups in many different arenas, including not only academics but also sports,  chess  and business.  Not only has stereotype threat been widely criticized by on a theoretical basis,   but has failed several attempts to replicate it's experimental evidence.     The findings in support of the concept have been suggested by multiple methodological reviews to be the product of publication bias.   Stereotypes lead people to expect certain actions from members of social groups. These stereotype-based expectations may lead to self-fulfilling prophecies, in which one's inaccurate expectations about a person's behavior, through social interaction, prompt that person to act in stereotype-consistent ways, thus confirming one's erroneous expectations and validating the stereotype.    Word, Zanna, and Cooper (1974) demonstrated the effects of stereotypes in the context of a job interview. White participants interviewed black and white subjects who, prior to the experiments, had been trained to act in a standardized manner. Analysis of the videotaped interviews showed that black job applicants were treated differently: They received shorter amounts of interview time and less eye contact; interviewers made more speech errors (e.g., stutters, sentence incompletions, incoherent sounds) and physically distanced themselves from black applicants. In a second experiment, trained interviewers were instructed to treat applicants, all of whom were white, like the whites or blacks had been treated in the first experiment. As a result, applicants treated like the blacks of the first experiment behaved in a more nervous manner and received more negative performance ratings than interviewees receiving the treatment previously afforded to whites.  A 1977 study by Snyder, Tanke, and Berscheid found a similar pattern in social interactions between men and women. Male undergraduate students were asked to talk to female undergraduates, whom they believed to be physically attractive or unattractive, on the phone. The conversations were taped and analysis showed that men who thought that they were talking to an attractive woman communicated in a more positive and friendlier manner than men who believed that they were talking to unattractive women. This altered the women's behavior: Female subjects who, unknowingly to them, were perceived to be physically attractive behaved in a friendly, likeable, and sociable manner in comparison with subjects who were regarded as unattractive.  A 2005 study by J. Thomas Kellow and Brett  D. Jones looked at the effects of self-fulfilling prophecy on African American and Caucasian high school freshman students. Both white and black students were informed that their test performance would be predictive of their performance on a statewide, high stakes standardized test. They were also told that historically, white students had outperformed black students on the test. This knowledge created a self-fulfilling prophecy in both the white and black students, where the white students scored statistically significantly higher than the African American students on the test. The stereotype threat of underperforming on standardized tests effected the African American students in this study.  Because stereotypes simplify and justify social reality, they have potentially powerful effects on how people perceive and treat one another.  As a result, stereotypes can lead to discrimination in labor markets and other domains.  For example, Tilcsik (2011) has found that employers who seek job applicants with stereotypically male heterosexual traits are particularly likely to engage in discrimination against gay men, suggesting that discrimination on the basis of sexual orientation is partly rooted in specific stereotypes and that these stereotypes loom large in many labor markets.  Agerström and Rooth (2011) showed that automatic obesity stereotypes captured by the Implicit Association Test can predict real hiring discrimination against the obese.  Similarly, experiments suggest that gender stereotypes play an important role in judgments that affect hiring decisions.   Stereotypes can affect self-evaluations and lead to self-stereotyping.   For instance, Correll (2001, 2004) found that specific stereotypes (e.g., the stereotype that women have lower mathematical ability) affect women's and men's evaluations of their abilities (e.g., in math and science), such that men assess their own task ability higher than women performing at the same level.   Similarly, a study by Sinclair et al. (2006) has shown that Asian American women rated their math ability more favorably when their ethnicity and the relevant stereotype that Asian Americans excel in math was made salient. In contrast, they rated their math ability less favorably when their gender and the corresponding stereotype of women's inferior math skills was made salient. Sinclair et al. found, however, that the effect of stereotypes on self-evaluations is mediated by the degree to which close people in someone's life endorse these stereotypes. People's self-stereotyping can increase or decrease depending on whether close others view them in stereotype-consistent or inconsistent manner.  Stereotyping can also play a central role in depression, when people have negative self-stereotypes about themselves, according to Cox, Abramson, Devine, and Hollon (2012).  This depression that is caused by prejudice (i.e., "deprejudice") can be related to a group membership (e.g., Me–Gay–Bad) or not (e.g., Me–Bad). If someone holds prejudicial beliefs about a stigmatized group and then becomes a member of that group, they may internalize their prejudice and develop depression. People may also show prejudice internalization through self-stereotyping because of negative childhood experiences such as verbal and physical abuse.  Stereotypes are traditional and familiar symbol clusters, expressing a more or less complex idea in a convenient way. They are often simplistic pronouncements about gender, racial, ethnic, and cultural backgrounds and they can become a source of misinformation and delusion. For example, in a school when students are confronted with the task of writing a theme, they think in terms of literary associations, often using stereotypes picked up from books, films, and magazines that they have read or viewed. The danger in stereotyping lies not in its existence, but in the fact that it can become a substitute for observation and a misinterpretation of a cultural identity.  Promoting information literacy is a pedagogical approach that can effectively combat the entrenchment of stereotypes. The necessity for using information literacy to separate multicultural "fact from fiction" is well illustrated with examples from literature and media.  Stereotypes are common in various cultural media, where they take the form of dramatic stock characters. The instantly recognizable nature of stereotypes mean that they are effective in advertising and situation comedy.  Alexander Fedorov (2015) proposed a concept of media stereotypes analysis. This concept refers to identification and analysis of stereotypical images of people, ideas, events, stories, themes and etc. in media context.  The characters that do appear in movies greatly effect how people worldwide perceive gender relations, race, and cultural communities. Because approximately 85% of worldwide ticket sales are directed toward Hollywood movies, the American movie industry has been greatly responsible for portraying characters of different cultures and diversity to fit into stereotypical categories.  This has led to the spread and persistence of gender, racial, ethnic, and cultural stereotypes seen in the movies.  For example, portrayals of Latin Americans in film and print media are restricted to a narrow set of characters. Latin Americans are largely depicted as sexualized figures such as the Latino macho or the Latina vixen, gang members, (illegal) immigrants, or entertainers. By comparison, they are rarely portrayed as working professionals, business leaders or politicians.  In Hollywood films, there are several Latin American stereotypes that have historically been used. Some examples are El Bandido, the Halfbreed Harlot, The Male Buffoon, The Female Clown, The Latin Lover, The Dark Lady, The Wise Old Man, and The Poor Peon. Many hispanic characters in hollywood films consists of one or more of these basic stereotypes, but it has been rare to view Latin American actors representing characters outside of this stereotypical criteria.  Media stereotypes of women first emerged in the early 20th century. Various stereotypic depictions or "types" of women appeared in magazines, including Victorian ideals of femininity, the New Woman, the Gibson Girl, the Femme fatale, and the Flapper.   Stereotypes are also common in video games, with women being portrayed as stereotypes such as the "damsel in distress" or as sexual objects (see Gender representation in video games).  Studies show that minorities are portrayed most often in stereotypical roles such as athletes and gangsters (see Racial representations in video games).  In literature and art, stereotypes are clichéd or predictable characters or situations. Throughout history, storytellers have drawn from stereotypical characters and situations to immediately connect the audience with new tales.       